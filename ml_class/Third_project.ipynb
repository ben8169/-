{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j5JUoFOdgoh8"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow pandas scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rehBcReIhThE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 로드\n",
        "# df = pd.read_csv('/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train.csv')\n",
        "df = pd.read_csv('./skku-2024-1-machine-learning-third-project/train.csv')\n",
        "\n",
        "# train-test 분리\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDS68RlswPCy",
        "outputId": "2b4c74ed-b5ed-42a1-cba1-b15895029790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3785, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RfOX_KM-6DsK",
        "outputId": "bd29b47e-b0a0-4f5e-ffce-001dce41e248"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6417.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6418.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6420.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6422.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6425.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>7132.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>7134.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>7135.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>7136.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>7138.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_name\n",
              "0     6417.jpg\n",
              "1     6418.jpg\n",
              "2     6420.jpg\n",
              "3     6422.jpg\n",
              "4     6425.jpg\n",
              "..         ...\n",
              "435   7132.jpg\n",
              "436   7134.jpg\n",
              "437   7135.jpg\n",
              "438   7136.jpg\n",
              "439   7138.jpg\n",
              "\n",
              "[440 rows x 1 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df2 = pd.read_csv(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test.csv\")\n",
        "df2 = pd.read_csv(\"skku-2024-1-machine-learning-third-project/test.csv\")\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IfYzTHIssx-D"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# dir = r\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/SceneImages\"\n",
        "\n",
        "# # train_lst = df['image_name'].values.tolist()\n",
        "\n",
        "# # for i in train_lst:\n",
        "# #     shutil.move(dir+\"/\"+i,\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train\")\n",
        "\n",
        "# # files = os.listdir(dir)\n",
        "# # for i in (files):\n",
        "# #     shutil.move(dir+\"/\"+i,\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test\")\n",
        "\n",
        "# print(len(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train\")))\n",
        "# print(len(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test\")))\n",
        "# print(len(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/SceneImages\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCkmpwM0wV8k",
        "outputId": "97bb70b2-8876-4c96-dec3-8cbf8b5affad"
      },
      "outputs": [],
      "source": [
        "# print(set(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train\")) == set(df['image_name'].values.tolist()))\n",
        "# print(set(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test\")) == set(df2['image_name'].values.tolist()))"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://discuss.pytorch.org/t/input-size-for-efficientnet-versions-from-torchvision-models/140525"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(384, 380)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sizes = {\n",
        "    'b0': (256, 224), 'b1': (256, 240), 'b2': (288, 288), 'b3': (320, 300),\n",
        "    'b4': (384, 380), 'b5': (489, 456), 'b6': (561, 528), 'b7': (633, 600),\n",
        "}\n",
        "resoultion = sizes['b4']\n",
        "resoultion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bvj4Gr16hk2O"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 이미지 변환 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(resoultion),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomResizedCrop(size=resoultion, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# train_dataset = CustomDataset(train_df, '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "# val_dataset = CustomDataset(val_df, '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "train_dataset = CustomDataset(train_df, 'skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "val_dataset = CustomDataset(val_df, 'skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_vz2uxQh3Ct",
        "outputId": "209d6bc0-b2a3-4e53-b439-aec4ce2c6cd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# 모델 정의\n",
        "model = models.efficientnet_b4(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(train_df['label'].unique()))\n",
        "\n",
        "# GPU 사용 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('b4_resoultion_changed.pth',\n",
              " './skku-2024-1-machine-learning-third-project/b4_resoultion_changed.csv')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project_name = 'b4_resoultion_changed'\n",
        "\n",
        "model_save_path = project_name+'.pth'\n",
        "df_save_path = './skku-2024-1-machine-learning-third-project/' + project_name + '.csv'\n",
        "model_save_path, df_save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5tKSWU8xHEo",
        "outputId": "2e31d43a-f90b-4d6f-8ea9-b4d87ce5450e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3JYxyL9h4oP",
        "outputId": "fa357bef-bbf6-475b-c1a3-4af137a0c4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/99, Loss: 1.0642, Acc: 0.6830, Val Acc: 0.8573\n",
            "Epoch 1/99, Loss: 0.3850, Acc: 0.8603, Val Acc: 0.8943\n",
            "Epoch 2/99, Loss: 0.2810, Acc: 0.8993, Val Acc: 0.8956\n",
            "Epoch 3/99, Loss: 0.2481, Acc: 0.9164, Val Acc: 0.9036\n",
            "Epoch 4/99, Loss: 0.2205, Acc: 0.9240, Val Acc: 0.9062\n",
            "Epoch 5/99, Loss: 0.1886, Acc: 0.9369, Val Acc: 0.9221\n",
            "Epoch 6/99, Loss: 0.1585, Acc: 0.9425, Val Acc: 0.9273\n",
            "Epoch 7/99, Loss: 0.1524, Acc: 0.9455, Val Acc: 0.9115\n",
            "Epoch 8/99, Loss: 0.1206, Acc: 0.9581, Val Acc: 0.9247\n",
            "Epoch 9/99, Loss: 0.1122, Acc: 0.9600, Val Acc: 0.9155\n",
            "Epoch 10/99, Loss: 0.0871, Acc: 0.9723, Val Acc: 0.9168\n",
            "Epoch 11/99, Loss: 0.0902, Acc: 0.9680, Val Acc: 0.9207\n",
            "Epoch 12/99, Loss: 0.0798, Acc: 0.9696, Val Acc: 0.9207\n",
            "Epoch 13/99, Loss: 0.0616, Acc: 0.9789, Val Acc: 0.9168\n",
            "Epoch 14/99, Loss: 0.0511, Acc: 0.9825, Val Acc: 0.9221\n",
            "Epoch 15/99, Loss: 0.0468, Acc: 0.9868, Val Acc: 0.9207\n",
            "Epoch 16/99, Loss: 0.0429, Acc: 0.9884, Val Acc: 0.9022\n",
            "Epoch 17/99, Loss: 0.0340, Acc: 0.9898, Val Acc: 0.9128\n",
            "Epoch 18/99, Loss: 0.0416, Acc: 0.9838, Val Acc: 0.9128\n",
            "Epoch 19/99, Loss: 0.0297, Acc: 0.9901, Val Acc: 0.9273\n",
            "Epoch 20/99, Loss: 0.0296, Acc: 0.9898, Val Acc: 0.9049\n",
            "Epoch 21/99, Loss: 0.0262, Acc: 0.9917, Val Acc: 0.9128\n",
            "Epoch 22/99, Loss: 0.0342, Acc: 0.9888, Val Acc: 0.9168\n",
            "Epoch 23/99, Loss: 0.0263, Acc: 0.9911, Val Acc: 0.9273\n",
            "Epoch 24/99, Loss: 0.0226, Acc: 0.9921, Val Acc: 0.9168\n",
            "Epoch 25/99, Loss: 0.0258, Acc: 0.9924, Val Acc: 0.9102\n",
            "Epoch 26/99, Loss: 0.0230, Acc: 0.9937, Val Acc: 0.9287\n",
            "Epoch 27/99, Loss: 0.0223, Acc: 0.9921, Val Acc: 0.9247\n",
            "Epoch 28/99, Loss: 0.0180, Acc: 0.9944, Val Acc: 0.9234\n",
            "Epoch 29/99, Loss: 0.0211, Acc: 0.9927, Val Acc: 0.9194\n",
            "Epoch 30/99, Loss: 0.0138, Acc: 0.9957, Val Acc: 0.9141\n",
            "Epoch 31/99, Loss: 0.0117, Acc: 0.9964, Val Acc: 0.9181\n",
            "Epoch 32/99, Loss: 0.0203, Acc: 0.9937, Val Acc: 0.9128\n",
            "Epoch 33/99, Loss: 0.0230, Acc: 0.9924, Val Acc: 0.9234\n",
            "Epoch 34/99, Loss: 0.0190, Acc: 0.9934, Val Acc: 0.9102\n",
            "Epoch 35/99, Loss: 0.0144, Acc: 0.9957, Val Acc: 0.9036\n",
            "Epoch 36/99, Loss: 0.0092, Acc: 0.9977, Val Acc: 0.9102\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=200):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_running_corrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        if val_acc > best_acc and epoch>45:\n",
        "            best_acc = val_acc\n",
        "            # torch.save(model.state_dict(), '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/best_model_200_twoaug.pth')\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "    print('Best Val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "# 모델 학습\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpaR43srh7I7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to predictions.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# 모델 로드\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/best_model_200_twoaug.pth'))\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "# 이미지 변환 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(resoultion),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    return preds.item()\n",
        "\n",
        "# 예측할 이미지 리스트 생성\n",
        "image_names = df2['image_name'].values.tolist()\n",
        "\n",
        "# 예측 결과 저장을 위한 리스트\n",
        "results = []\n",
        "\n",
        "# 예측 및 결과 저장\n",
        "for image_name in image_names:\n",
        "    image_path = os.path.join('./skku-2024-1-machine-learning-third-project/test', image_name)\n",
        "    predicted_class = predict_image(image_path, model)\n",
        "    results.append({'image_name': image_name, 'label': predicted_class})\n",
        "\n",
        "# 리스트를 데이터프레임으로 변환\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "# 결과 CSV 파일로 저장\n",
        "# result_df.to_csv('/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/predictions_200.csv', index=False)\n",
        "result_df.to_csv(df_save_path, index=False)\n",
        "\n",
        "print(df_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z7yXH2l_xukc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6417.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6418.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6420.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6422.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6425.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>7132.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>7134.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>7135.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>7136.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>7138.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_name  label\n",
              "0     6417.jpg      0\n",
              "1     6418.jpg      3\n",
              "2     6420.jpg      0\n",
              "3     6422.jpg      2\n",
              "4     6425.jpg      5\n",
              "..         ...    ...\n",
              "435   7132.jpg      5\n",
              "436   7134.jpg      4\n",
              "437   7135.jpg      4\n",
              "438   7136.jpg      4\n",
              "439   7138.jpg      0\n",
              "\n",
              "[440 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MDvDBCOB4f9H",
        "outputId": "abe964cf-57d8-4b2c-d1d7-aeef486f5723"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/submission.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df3\n",
            "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/submission.csv'"
          ]
        }
      ],
      "source": [
        "df3 = pd.read_csv(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/submission.csv\")\n",
        "df3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# 모델 로드 및 출력층 수정\n",
        "def load_model(model_name, num_classes):\n",
        "    if model_name == 'efficientnet_b7':\n",
        "        model = models.efficientnet_b7(pretrained=True)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    elif model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif model_name == 'densenet121':\n",
        "        model = models.densenet121(pretrained=True)\n",
        "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type\")\n",
        "    return model\n",
        "\n",
        "# 모델 목록\n",
        "model_names = ['efficientnet_b7', 'resnet50', 'densenet121']\n",
        "num_classes = 6\n",
        "models_list = [load_model(name, num_classes) for name in model_names]\n",
        "\n",
        "# 옵티마이저 및 손실 함수 정의\n",
        "optimizers = [optim.Adam(model.parameters(), lr=1e-3) for model in models_list]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 모델 학습 함수\n",
        "def train_model(model, optimizer, num_epochs=10):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
        "    return model\n",
        "\n",
        "# 모델 학습\n",
        "trained_models = [train_model(model, optimizer) for model, optimizer in zip(models_list, optimizers)]\n",
        "\n",
        "# 앙상블 예측 함수\n",
        "def ensemble_predict(models, inputs):\n",
        "    outputs = [model(inputs) for model in models]\n",
        "    avg_output = torch.mean(torch.stack(outputs), dim=0)\n",
        "    return avg_output\n",
        "\n",
        "# 모델 평가\n",
        "def evaluate(models):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for model in models:\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = ensemble_predict(models, inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "accuracy = evaluate(trained_models)\n",
        "print(f\"Ensemble Accuracy: {accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
