{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- wandb 쓰기\n",
        "- 앙상블 하기\n",
        "- "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Currently logged in as: ben8169. Use `wandb login --relogin` to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((224, 224), '9')"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sizes = {\n",
        "    'b0': (224, 224), 'b1': (256, 240), 'b2': (288, 288), 'b3': (320, 300),\n",
        "    'b4': (384, 380), 'b5': (489, 456), 'b6': (561, 528), 'b7': (633, 600),\n",
        "}\n",
        "resolution = sizes['b0']\n",
        "trial = '9'\n",
        "resolution, trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rehBcReIhThE"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 로드\n",
        "# df = pd.read_csv('/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train.csv')\n",
        "df = pd.read_csv('./skku-2024-1-machine-learning-third-project/train.csv')\n",
        "\n",
        "# train-test 분리\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDS68RlswPCy",
        "outputId": "2b4c74ed-b5ed-42a1-cba1-b15895029790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3785, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RfOX_KM-6DsK",
        "outputId": "bd29b47e-b0a0-4f5e-ffce-001dce41e248"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6417.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6418.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6420.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6422.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6425.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>7132.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>7134.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>7135.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>7136.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>7138.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_name\n",
              "0     6417.jpg\n",
              "1     6418.jpg\n",
              "2     6420.jpg\n",
              "3     6422.jpg\n",
              "4     6425.jpg\n",
              "..         ...\n",
              "435   7132.jpg\n",
              "436   7134.jpg\n",
              "437   7135.jpg\n",
              "438   7136.jpg\n",
              "439   7138.jpg\n",
              "\n",
              "[440 rows x 1 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df2 = pd.read_csv(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test.csv\")\n",
        "df2 = pd.read_csv(\"skku-2024-1-machine-learning-third-project/test.csv\")\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IfYzTHIssx-D"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# dir = r\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/SceneImages\"\n",
        "\n",
        "# # train_lst = df['image_name'].values.tolist()\n",
        "\n",
        "# # for i in train_lst:\n",
        "# #     shutil.move(dir+\"/\"+i,\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train\")\n",
        "\n",
        "# # files = os.listdir(dir)\n",
        "# # for i in (files):\n",
        "# #     shutil.move(dir+\"/\"+i,\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test\")\n",
        "\n",
        "# print(len(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train\")))\n",
        "# print(len(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test\")))\n",
        "# print(len(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/SceneImages\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCkmpwM0wV8k",
        "outputId": "97bb70b2-8876-4c96-dec3-8cbf8b5affad"
      },
      "outputs": [],
      "source": [
        "# print(set(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train\")) == set(df['image_name'].values.tolist()))\n",
        "# print(set(os.listdir(\"/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/test\")) == set(df2['image_name'].values.tolist()))"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt4AAAFjCAIAAACFSps+AAAgAElEQVR4Ae2dz4sbR9rH86/oILBOM6e5OeQyzMFhYW0C64UXInSQ2YNDYMO+8C7OskaBhhxy8MFg8MHgg0AQgiGEQDCG4PgwQgcbQzCGYAcGNBAYQ2AOhn6pqq6qp/qHRqNpqbvVnyV4StXVVU99nq5H3/rR2g9i/gcBCEAAAhCAAARqQ+CD2liCIRCAAAQgAAEIQCBGmvAQQAACEIAABCBQIwJIkxo5A1MgAAEIQAACEECa8AxAAAIQgAAEIFAjAkiTGjkDUyAAAQhAAAIQQJrwDEAAAhCAAAQgUCMCSJMaOQNTIAABCEAAAhBAmpzzGTia9LvR9Jw31a/4bNQdjo/OsGsa9fqT4zMKLXN5S6DJrh6PB73RoczZ4vSCzp6+evjF3k6v09377Ef1qLz5/va1PfXxxqO3W0ykiq4t8EKp5syfjD7Z63R7lw7uvyi14rIr2xSQsu2upL75ZNiJZrlNz59Eeszu7t97mVugksyzpYnqUrcn/7vo15X6ovIV7hx8+tm9Z/P3rvunryYmuu3uDe8+nbv8EhJhX/b2P/3i3i/2q/cwkn1M0oNJuv0t+ZZtmjT5/cm9ycvTEh6BsqpoVVgMOvvmp/vj59YVv97f37n9+CSO35+evo/j3x5e6w4f/GY/lgX7wvXkxuXSlHeueX++HN978saHtdxC58qUXjh9Mbn/+Pdz3b5k4Xc//O/utfuvVelT62VzK2NwSYS1LJY7BJSlJz/+a+f6vV9VMuXwavuxnDQpUFsrmi6/3d+fzl8/unXQ27+b6LWT77+4dHD78e+n8fvTV99+8eHBN9NwgOhG3/3w+dmT/qx5gXv+PH716PZ+98od0/L705M/3on/jh9/ddlZ5auSxvvcxqXWLE1e3v1QPjMXhnby478vHdx/tT7MKYPPbkh+T5xduuElZGfVV9f+Pf3VFcdqQH35xA3Qk++/6GTV/Bo7v2wcCAa+tWe90kSJtn//cGIbK+Gv9MLrewe7//rx3YJaT77/YqU55GzUvfogcW9QPWMwwFHRh1XdqoeqjMnO/sOo89eHawytrqFzJqqWJtrcN+NPbUR7++CT3Vs/u1j37rubvc++z4zA97PRzoWliWr67fh/CvYs/nh0o3vzuz8yOC/8LZupsZKM9UqT9DdB7aGlDT7bJ/J74uzSDS9R2NkUN/Vxk9Jk6TiQstO4Y73SpHyXF3oht6lptLuqNFkltObacK7MXB8trOF8QBZW1ZiLq7p1oTTZ5JhdmvQFpMn746d3bu6rfeXezsHNO25nJI6nUW90ePri3lBtQme7nfmiUtLk8x/VBOPkx8+6w+/EJsqrB1cvfRPukP36UG+MJVtCdvjpbaDLu2qL9PL1W5PXTt1IFJmnX0mTHOkTx28eXr/032c5lWjjH/86uWW2Yy8PZcdPj57d++d1vfXe2/nkiwdu3Xv+7M4/ruyobazdvb/cvHNoxZbL37ncj/KXfxXMX97+8KWududy/97L0/dvvzMfu3vXvvxRLBovgjD/5e6NA7WFvHNw897zJ8FZkwIzZOx2t3d2Ln/8j7vTwungu8dfXr7kN+z0uZw0tNBB/kHa3RtGj3+THrPpw8g9SBrI8dM7+unq7u3/Q+z6HU36g8mrfO/MRt3gdIh9GPIMts2qv3++Hie0e2rzMTlCocPiT+qScuvO5WtfTl79mdxW+BgsMi+Oizg476QeHm/kuxffRsa5nfBByh2Jp79Obv1N+2jv+mcPZyd5mw6ujBpN3z+TB2vsU/H6ganE+Dr68fF/zROuB2Yy6v0DqYbDzD72msOb3380gyg5slPU/cOoEz2b/3K3r0e3DzX5ccBDkSnra5mnwpSNHirfdbkTYDkeD4bj39UAVI5O5p0F/ZLVyyh3AQ+KKuU3sUjnPJ+vH+joVLgrHXv7ZbQ8+em2ief6xoxAEWMwLnJKHMeLHvLGjkHhhqJH5fSX6MODaGqDwJvJ8NJgooOzfoR+9bGifydzgME823KMxHE8d98mu3t/++bpSb5bC55bEbhUdPrx6Th71uRd3pgVAyEMa9rps9Pn9/VIzDweIaKLf1pZmpxOoyuXhg9f6HWF09eP/nVwZXSYfJWrMT+8eePu7M0f705OMt/vctC+Pz357cktd6+8pDunYsrwkdAqOlcVC9Co58BsA8Vx/Mfszt/2+pOcU3hBhDp99+an2/viYfI037+889H+nec+w6dU07sff/Xkje7WyfOH/R27JaSafvn48K3adI/jkyfRhx/d1efIjr8b9voPX5v8099evjKLMaezrw+u3PpJl39//Pi/V3LF0DTqXdq7+eC5DutHP976aPfjv3w6+ll/PHk2OujdeJRE/EUQXt7d715PJNHp2x/+e+WSA1hsho/d80f97vCB0XvvT988f12oTDSpaeSCuP6soe3/76NXGtrp60l/54rZ3Yzj0+k3V/b/m/Cc/3R7f+f208wjo0aF1bgKyM71O4fHiqfh9r9a15qwmPHO1zNTXVFYVBamDdZWm3+m3+x++NUT8/19On/94ndTm/puuHTw7+8Mk9PX46Hf5ih4DHTULjSviEPBwyMsjOP41S9P7EP1+sHAq+2ckXj0qL83TB6nk5cPhrvXHmZGyh8/fraz/9m3+ol9/+7F/eGlHa/q/FNhNnTEKrEaX9ZNKrR+O9yxIeLk5cP+znV1DMW46a/D/qe3v3t9fPLHOz0uirofK9fv7F67M5tr8PoJsRslmTgQUvGfgoFvs2VH4kIsx+PB1f7w01uPXs//eHeiv3gK+2VrVn+Vbea8/IU8KKoUciT26QXPpxReop54UaCIi9dTxRg8yynpCNnwMSjhxcWPivpO3I90uPl90t8bjpPDQDpW/CVSpxT0d8SD4e7+N0lUKnyW/pyNDnb7D16qx/703fy3Y32zqipwa+Fz++6Hz3c//DwJuSfP7/d3dq2wDrsj3RrH8e8qONtvpXfTu9d3hkZg6ZE4GN64eXf6mzr5YL7OwrrK/LScNPGT4F7HfKXp7yr5isfJo5suKqlAf/NR4beXGrT+GGyne330JPk618fogvdfUsEu6Xo6JM2+3tkNXpd4fvfDnWiamQ6q2mTTf4se/2a+aQKmqi+fPHwT5NkP6abjF3f2L4nobMvF8emTW8kKkIlN6S8AtTEv9unj3yd/795+nDFHfROL+hVbcderB1ftA7cIwjTalZXouJlouwVm+NhtpEnueobvsE+lv+nT0E4ff9nrf6sPIKt1MtlrtY51y59esHWK8ZMCEr9++PHON8k7U+mGpHcuIk2eZZYW0jHi9MntHA2tZljuMTBfV4Gk9g9PIYf8h8dyyfkrFxqzI/HF3f2P5VGCX3J2mtODTu2brCBNXt75KDi18PSrXtK0clMo/Qu7b6SJHMuvH/x192uzkJpxdw4OnZUe+DYIuChfjEU5+sPkPJqpvrhfsnllm5Qm6eEvy6bS0oPikrLERjmf1tLk7OdT1LMoUMTnkCbLOsU/5Kpy1wVlkfKLDW7poCEsXrKPaxuDwpQ4Ln5U4ljpif3Rzy/HQzk3TseK2H89FT5L828DlW8tSFdVaExmaEyjpaTJ9Jvwm0LN0u13q3pTJO+QgzWu3L/LSRP79Pi2lZWBhlDfEDbHf6X5G0TKD1qd+edbtWBglkZSl8yze+aqScYN5vtAKifTvBwJ6ltDLdjsJt+R3kB93iX77WgK5FroZoonL7+Lbn781ys7O5c//stlvzKh1653Pvni68nMLLckM3UbIq1gCr63TIMpmNPIxnd92fdoEYT0Ay0DkIoIBWbIpvVLoXvX/vnN2C4LeWCZVDrKZKD5mvNejHJfGL7iUJoEBWTlMq1vFgczVwyL8Z8v7w0v71we3npoVyZUzf67ITFSWBgXPQYLzFvAIe/h8WR0av7z/c8+vfrx5d2dg6tqTd4OWM85uUGZnXF3OJBz1pCCzso6/eNnzJCrJqqzmbaMYRkOahaeKZx4WYJVrQhjVD05Qybpq/iTstNcER1ZgEU0Z25b0C/Rolg1ieMLeFBUKS0R6eLnMxgmrqIsNK2ebbRcetXEBT1Vs7An49xtGIOOnu5p5lkVI0itT/cumfMJyV0CjsnR5xYU8OJnKR1CRVXCrarmfGMyX9C5Q0DVGowvVaGoX31Jqmmk+QmJoGRi0Pr+lCdNXt79cDVpoheR/m5CjPZZ6qyJi7OeQmp0pT7aMyt2sPn7su4RJ3Btsed31UZMZsUluZwZeKpOM0rVzshuf5xs3MiVCXPvyetnD768vrNz9Wu981Xw8Fkz7F8RQFVW6qPv0SII2QfOB6AFZqTait+/e/Xzw1uf7F36yzduS9WaGfxN15mB5mvODKGgIvdBjAp/r7kqK5dpfbWEsKjrOf395XfqdMvejW/N9DcTbpyFCx6DBeadxSH18DgwZt/k0kH01Gx4hMIizUoH1jD0yJqSdNp98osnfAL946dv9WMh2dEo0A0ZDlqaiPgujXJgk0xBXtVT0ISsIZyduysCTnaAuFKiOZO3ZKOZPq7mQWdH8PUfekR9geQ9n/mOztrvvilVYz4yiKZ1UjpCptVFQSnbcf/e1qrTA91+bh/tMlJo4XrGoG5jwaOirp8+uX1pZ/fSJw9f+W8QAUdXYY5UWmmS/wBnxqC5M9V66qMpo//NxJPUUPVFA1dmK3z3w+fNkibB06y6mdrQyR8Vhkfm2dUrLsZDx+PBEm/opEeXWHQyTfgVM++C1PqhuaA2RAL5r94Jytl9d9Wopj+1m4gq1y9Xpp4GtYyU89gpUHodSC3ZFW0buebCb4JF0iReBGEa7QaL0n88umFtW2CGiN3CoFghyiw1yQKZoxsZj/ua1VaRPYIQ1BF+EOPH32uKyMpVOthE8N7JLCbLFc6CQBDaEMd6JdZsHmXCjbNwwWOwwLzlOLiHR1iWiiZqluPUfJpVHKsF29zz3aJGFcXkhqxa1PXr8LLOVLwLpEmsNg7E23aiAekyk72g+w5sUoEgr+rJGWKipSSZstPkyo4UYxHNJZUV90s2nO2jvnpeD4oqpSUyLYqouOefz4IgvChQlCRNtnkMFj8q+hjKzvUHr989/WrfnSYxui3YRfVfT4XPUjiUnIuV36VbC41Rj1+w+fLizr4LC646lQjH14u74fmE1IZO8F0ZVFP6h1VXTfTpxUvDiT3YmDkGu+BXRMNBe3qkzuIlGzpGdR5ET/9Qv9qkjql+FOX8rona/N5PjoJqcTr/dqgmjuZ46ZLHYN+fztUh1nBDR/1mVODRNPGjSX9nd//LH3OOwepAmZwV/ePlg/+7up/EzbfTn14nc9r3755GV5JjH/qg07VvnpmqTk/evvgl53ipDKALpYk6dVgI4eXd/R17+PH07eOvrvrNpmIzfNO/zR6/1sdO1TGuZ6MDu/v4S2ZfT/PS4+qhOp1upg6hx8Ne6PPUf/vmqTkjdvruzfNnr7LHlMT48VYZ38jKVXp352byWJ4c3r3mfrcmVj/I8eGXP5of9zt5/vCzy3turKYN9l5/9+LJ7I05df/+9NVYnbrXh7Iz3w3OwsLHIDkGW2BeEYeCh8dbGCvdaQ7qqiET/f3Ax6A0K3vM7V+Tl8nB3qPXT5/bXx10dapjsP4o3IsHN3dWOWtijlv+e2xOcKtfMHr2wvwAsXRZ0mhR99OhM5igp+PAu8dfXr12Nzlg6HqTOycJH8Lk9F8eloyj4+J+ySZ9Hy/kQVGltMSli55P81ToMyh++p5UtihQlLNqsmVjUDhhwQh6/3Y83O2P9arqn89GH7n3QpSzLu3dHJsj83/M7nzif8dLH0nOGyN/Prm1o47BqnGqxs5bExT1YBdu1adW855bdQzWvV5w8vzhjb2lzpqoQ747V+x3a/YYbOY3SEM2JX5aWZrE8ft304dfmPd4/Rt92rScgChNVoNW7JDtXbkRPXIvXsbmxTb1TvLu3t9u/1Dwi4f297B3bzxKAuubnyLzeqF8HU42m0Qo0fTOwc3Ro+A1YzXJXjynPJr0P3/0ZnbfvYgrXx52VmnL347/x0zp3n73z0+Tt/JSr2P518PUO8+fPcz5wdMUzNTH1HRwAQT/+qV6q/m1eiXS/VB9gRm+rd8effZp8mqoxKu2w8SZXE9b73+rV4j37qoDqj5MJ0V8zbF+afbeF9f063PqLdx/PnyROQsspX1wb6py3dDj5/neid07nOYN218iJ03MgRJvsO/Ju+ndmx8b24IXld13gy3qpIn/sXbzALvHIOFQaN7746c5HIofHtuyMP7KjXsvT0S/0qz0Lae/Pholr7KrN8lHTzLSxLxJa1+PH/309qn6OYCkPVln6vHTCk8Gr9NXj+xbzYpe9LhQmhQ/BgKstiAg70acjgNKfe7835Ossk3ZaXoiO6KW4vOxBM0lCOKCftnL6q9/5i/kQVGltMSli57P5ICL+jGFm5k3HOO4OFCUs6FT+JA3cgwKJ+hk7qPyZjL0L7PE8elhtP9R9FTNarSzfnp5zwy6vSs3Ui8P544R9XUlfnLib/ZX0ewr986tucYoM/Vb5eanDdQvU4iwEPQnPb7i+Lcno6H+cYHUt1W2ZFBRyR/OliYlN0h120NA7R3k/ipMZV303weVmbCo4Zqbt8h0rkFgOQI1f8grMM/pyOUAUkoTQJrwIKxM4OWdg7zfIFm5vovfWEHcOY/RNTfvPF2hLATyCdT8Ia/APKRJ/pOyOBdpspgPVxtFoIK4cx4+NTfvPF2hLATyCdT8Ia/APKRJ/pOyOBdpspgPVxtFoIK4cx4+NTfvPF2hLATyCdT8Ia/APKRJ/pOyOBdpspgPVyEAAQhAAAIQ2CgBpMlGcdMYBCAAAQhAAAKLCSBNFvPhKgQgAAEIQAACGyWANNkobhqDAAQgAAEIQGAxAaTJYj5chQAEIAABCEBgowSQJhvFTWMQgAAEIAABCCwmgDRZzIerEIAABCAAAQhslMAGpclmf4E/RTH3/0QjVUb8316kr/AZAhCAAAQgAIHNEECaCM4V/BqPaJ0kBCAAAQhAAAJxjDQRTwHSRMAgCQEIQAACEKiEANJEYEeaCBgkIQABCEAAApUQWEaanL6a3L52ebfT7e188sWD2Ttr6LsX30Y3DvY63V5n53I/evLmvb0Sn756ZC/tXbnx7Vt1QZ81mf5yt2+qOrh555djd4NPHE36g8mr5/dNzTuf3P7h9/hklny8dHl47/mpLzx/ducfV3a6vU53b/8fd5/O/ZX4z9fjL6/v7Sjbrn3549PxsBPN7OWCHklp8uv9/Z2r9361d/AXAhCAAAQgAIGNEDhbmsy/He4MH774Q5lz8vJhf+f6g98S01798uSVzo9PXz8Y9D77PlEtbybDSwe3H/+mNMTpH2/fGMVwGHV2dq/dmZ1oBXPyc7S/8+8fTjK9VPpg9+Ovnrw5jeP3717cH3YOrl67OXmlBcmb8fDSR3dfGA3052x0sNt/8FJV+P701aN/7x9E0z9Nhe9++Hz3w88fmbtOnt/v7+w6aVLYo0CaPLz2ly++O8qYRwYEIAABCEAAAuskcKY0eXnno6sPXnsTnn7V+1h+tldePbh66RuzLDH7emd3dGgvuL9KmkRTv7Ly+sFfd792CxmumNIHw7HTBOqjMOD0yS17df7tsDOYiIWSd9/d7PUneiUmVUkcTyMnTYp7JKWJs4cEBCAAAQhAAAIbJHCWNFHf1j21ZSP/szsj85/vf/bp1Y8v7+4cXN3f6yXLEhlZkHQn/fJwwf9VdEofqI+3H/s9nNnISpNpZFu0vF49uJrYcBh1utHU5sdx7F8eXtCjVNPidpIQgAAEIAABCGyGwDLSRKxhCKPm3w4vHURP54lq8EJBfcHn3bK6NJEiY5E0eXF3fzlpkmdeHPO7JsK9JCEAAQhAAALVEDhLmsRqd+bWz37Vwpqp1jyS3ROVdfr4S7uG8X42KtrQCfZfll81yZcmJ99/sXBD5+Z35hyMtvjFHataCnuENLG+5S8EIAABCECgOgJnSpNYn2n99/i5PuL6/nT++tkLfRBkGu1++NUTcwT1zU/R3w/cd3/86sH1zsHtx78rQXN68vaVTpg3dMTRkItKk/h09vXBbn/8+rTgGOz+f/VZ2jg+ef7wxp47a1LYo2DV5FeOwVb3VNIyBCAAAQi0mMDZ0iSWbwKrd3Sjx+aM6p8v7w0vX+r2OntXbtx7efJL5F6BUbfY9407e1du/aRlTdkbOsprJ7MH/7y+4OVhdcm82Jwyz73bLHskz5r8ysvDLR4WdB0CEIAABKojsIw0qc46WoYABCAAAQhAoGUEkCYtczjdhQAEIAABCNSbANKk3v7BOghAAAIQgEDLCCBNWuZwugsBCEAAAhCoNwGkSb39g3UQgAAEIACBlhFAmrTM4XQXAhCAAAQgUG8CSJN6+wfrIAABCEAAAi0jgDRpmcPpLgQgAAEIQKDeBJAm9fYP1kEAAhCAAARaRgBp0jKH010IQAACEIBAvQkgTertH6yDAAQgAAEItIwA0qRlDqe7EIAABCAAgXoTQJrU2z9YBwEIQAACEGgZAaRJyxxOdyEAAQhAAAL1JoA0qbd/sA4CEIAABCDQMgJIk5Y5nO5CAAIQgAAE6k0AaVJv/2AdBCAAAQhAoGUEkCYtczjdhQAEIAABCNSbANKk3v7BOghAAAIQgEDLCCBNWuZwugsBCEAAAhCoNwGkSb39g3UQgAAEIACBlhFAmrTM4XQXAhCAAAQgUG8CSJN6+wfrIAABCEAAAi0jgDRpmcPpLgQgAAEIQKDeBJAm9fYP1kEAAhCAAARaRgBp0jKH010IQAACEIBAvQkgTertH6yDAAQgAAEItIwA0qRlDqe7EIAABCAAgXoTQJrU2z9YBwEIQAACEGgZAaRJyxxOdyEAAQhAAAL1JnCGNPkP/4MABCAAAQhAAAJrJiDFEtJkzbCpHgIQgAAEIACBswicW5rIG0hDAAIQqCGB//znPzW0CpMgAIEzCRjRIosttWoibyANAQhAoIYEkCY1dAomQWAZAkiTZShRBgIQaB4BpEnzfIbFENAEkCY8CBCAwHYSQJpsp1/pVQsIIE1a4GS6CIFWEkCatNLtdHobCCBNtsGL9AECEMgSQJpkmZADgUYQQJo0wk0YCQEInJsA0uTcyLgBAvUggDSphx+wAgIQKJsA0qRsotQHgQ0RQJpsCDTNQAACGyaANNkwcJqDQFkEWi1NplGv0x2OjxbBnE+GnW6vPzleVIhrEIBA/QhsUJrMRt1epxtNzwmB8HJOYBRvC4GypIkZmb2OGp/6v2hWf4RIk/r7CAshsDKBOkqTw0gqGKTJys7lxu0msDZp0oSVBqTJdj/c9K7lBGooTXTMOffiSsv9SPdbSKBcaWKHnJoZ9DrJwsnxeGCXUrq9zmAyTzCH+XaVxUwjzNLL6DDjkaNJX4memauzPzn2t/jK41iXTJZwZL6xTVsyDjd0fD3dnmuaaU3GB2RAoBkEcqVJIg6S+JCELJ1pwpTf4RWZInDlBxa5oaPTLubogGN2hIMK9e5POrwsqDya+dtd5c3wA1ZC4NwEypUmQoKkv92jaZxoETNKEx0QzYyGMFIgyVQDLynsJELSMzl03eaRSCSHQrLFksGc2XiyZ02Kmk7HjnMT5gYIQKAaAsXSxEYqHRaSr3w1OzLxQasTM4dRBVTmcoHFCJ1CaWLrt1O4OA7CyzmilrWnGq60CoG1E1ifNPHDz3fCjD29QJJIAasMdBkjR+ysRRRO15AcNwvli1iqCQZ8onJEuLErNDokmeYKmw6r8oaQggAEak5gkTSxQSAtF9wih4knYooVp5SEDCyJprmQNAlDjYxIQjClbai5BzAPAisSKFeaWDniJxzKLL8OGZ6QFflGH5gRaCc0YeGkf0avJEsgpmYrZYQ0MTW7FRf3MRz88vbCplO3rIiZ2yAAgY0TWCBNXHAIdn7t+muwsqszTXkXSUxXxEcTQC4kTURtqnrxUVYex048bZwnDUJgYwTWI02EgDBf7cm5k7yFkKSAUhtyolBAQNRsR2+ONAn1hKhWyJfwdlEmbDmsKrzGJwhAoMYElpImwYJHXmdM0Mg5GiKDhlQPMh1u2WTakuFFpuMgGAYVIk3ynETethEoV5rkLHiY8aaliRlgyfFYna8mGaKATZtdHhURrOxw2JeTJjkzoWShxdpgp0euicSMTNMmP9lpdmaQgAAEak9gOWnilnVdONKLHy7+GGliAoiJPz56uOOxUj0YyRIEQxtA5CXXnD04slTlrJrU/rHDwDIIrE2apLdy1UAdHeqRGZw1MQNYxwLTn2SOYvJXlSbxUm/oTNXPqYkm8ppGmpTxmFEHBCogsKQ0cYdIkhf6zFG2vGig+iAFhN1ZTh9Y8WWG4yOlWqw0SYSFbigjTZasXBvmK6yAK01CYO0EypImazeUBiAAAQici0CuNDlXDRSGAAQqIYA0qQQ7jUIAAmsngDRZO2IagMB6CCBN1sOVWiEAgaoJIE2q9gDtQ2BFAkiTFcFxGwQgUHMCSJOaOwjzIFBEAGlSRIZ8CECg2QSQJs32H9a3mADSpMXOp+sQ2GoCSJOtdi+d22YCSJNt9i59g0CbCSBN2ux9+t5oAkiTRrsP4yEAgUICSJNCNFyAQL0JIE3q7R+sgwAEViWANFmVHPdBoGICSJOKHUDzEIDAmgggTdYElmohsG4CK0oTcxv/QgACEIAABCAAgXUQkALoA/khmzbNZ/PJgQAEIFArAqya1ModGAOB5QlklQbSZHl6lIQABOpLAGlSX99gGQQWEkCaLMTDRQhAoLEEkCaNdR2Gt50A0qTtTwD9h8C2EkCabKtn6dfWE0CabL2L6SAEWkoAadJSx9Pt5hNAmjTfh/QAAhDII4A0yaNCHgQaQABp0gAnYSIEILACAaTJCtC4BQJ1IIA0qYMXsAECECifANKkfKbUCIGNEECabDhUUl8AACAASURBVAQzjUAAAhsngDTZOHIahEA5BNYuTeaTYafb63SH46M4Ppr0VbrXiWblmE8tEIAABAoIIE0KwJANgboTKEuaHI8HWnMY5dHtjQ51z5UWiaYJBFUmyY9lOstoNnI1ZC8uzJlPhraJONatpGTQNHI2FFR0NOkL5TSNgn71J8fuNqu6ep3BZO5ySUAAAvUgUCBNVHjR86Vg5PrhnBt89LRKxJZ69BArILClBEqUJnpdJIXpaNL3X9vH40FemdQtF/sYKg/VYt/rIVV1WCCvscNIqpmwvNBMh5FTJCqoCTWTVyl5EIDApgnkSpNp5CZLKhokk42jycjNOoIJlbH5eDyIRmfOajbdP9qDwNYSWKM0kbOQfhQlWzldM1MJV00Oo2QSk8xXAhHj1y28ypmNBpNpslXU6yQLM8HKjZ7fqIAyDQNNIDX0TMg0beZD0majNoLyQtmE+bORXxza2meFjkGgWQRypYnsQsGkYjYyG9C2qBns4ZC31/gLAQisgcAapYmytnDVREgTpUv8PEb30UsTGTtEWq1euL0VkS+qVRUl9YgCctVEBiCfloXTqyxKypiFn/yG1uAgqoQABFYkcKY08asmsoVwMhPbZVSkiYREGgJrJVCiNLHbt2of10qNJaRJXnRw0iRUAL62cJXCxg5zuETsB+fU4+OL2JGREiQrTdyKju+XFT3WN6GdNpe/EIBAhQTOkCZhBLB2psayDzU+dNii/IUABNZEoERpkneOxIsJv4ahe+LGv0vIDjpJIQ6sJSfXjOjx8ULddrY0MS8HqXtdfFESxJ2G0wmzDJOVJkLruNWalNnOYNkL0hCAQJUEFkmTnMXa5OC8W451y66mDy50VNkl2oZAOwhULk28VhDA3Te9S4iLKnl+aRLHRnP4+OIFTVD5QmmSVCJXWfTNoT1BfXyAAASqIVAoTZZaLxE/diDnMBx4r8aZtNouAtVLE7Xm4c+3GvpekaSEgnVOKAW8yFi8mKGu9gfu7WJ/vsRWq/6mWvRSRl3UNZiT/MLs1C2yNtIQgEBVBPKliRi5wrBU6BBXbDIMBTaXvxCAwBoIlChN5FkT+9shZ2/oqD6pr/ZkXuIOmfrtIXHV/VZbkTTRmzu6KvuGjq9HtaRfyUlt0IRNmyUZ3Rc9PfLvBxkLxZzJG5aWVmtwFFVCAALnJJAnTfL3iP1YtgskYlsnaRVpck78FIfA6gTKkiarW8CdEIAABNZBIE+arKMd6oQABEomgDQpGSjVQQACNSGANKmJIzADAuclgDQ5LzHKQwACzSCANGmGn7ASAhkCSJMMEjIgAIGtIIA02Qo30ok2EkCatNHr9BkCbSCANGmDl+njVhJAmmylW+kUBCAQI014CCDQUAJIk4Y6DrMhAIEzCCBNzgDEZQjUlQDSpK6ewS4IQOBiBJAmF+PH3RCojADSpDL0NAwBCKyVANJkrXipHALrI4A0WR9baoYABKokgDSpkj5tQ+ACBJAmF4DHrRCAQI0JIE1q7BxMg8AiAitKE3Mb/0IAAhCAAAQgAIF1EJDi5QP5IZs2zWfzyYEABCBQKwKsmtTKHRgDgeUJZJUG0mR5epSEAATqSwBpUl/fYBkEFhJAmizEw0UIQKCxBJAmjXUdhredANKk7U8A/YfAthJAmmyrZ+nX1hNAmmy9i+kgBFpKAGnSUsfT7eYTQJo034f0AAIQyCOANMmjQh4EGkAAadIAJ2EiBCCwAgGkyQrQuAUCdSCANKmDF7ABAhAonwDSpHym1AiBjRBAmmwEM41AAAIbJ4A02ThyGoRAOQTWLk3mk2Gn2+t0h+OjOD6a9FW614lm5ZhPLRCAAAQKCCBNCsCQDYG6EyhLmhyPB1pzGOXR7Y0Odc+VFommCQRVJsmPZTrLaDZyNWQvLsyZT4a2iTjWraRk0DRyNhRUdDTpC+U0jYJ+9SfHwW2HUcd3MLjCBwhAoFoCBdJEhRc9X+p1BpN52kQdykQEsJOr3MLpm/kMAQiUQqBEaaLXRVJGHU36fvAfjwd5ZVK3XOxjqDxUi32vh1TVYYG8xg4jqWbC8oFmUjFrMBTaK6828iAAgYoI5EqTaeQmSyoapCYbam4TiQhwGDn5osa7kCwV9YlmIdAKAmuUJn620e31oyjZyumayUe4aqLWHpJ5jF7zCESMX7fwKmc2GkymyVZRz65b6OlOup5oGqzchNLEbTDZRRppswlDoTQRtyeLK7MRqyatGCl0snkEcqWJ7EZabZhpiZichMOfwS7hkYbAGgmsUZooqwtXTYQ0ydkT8dJExg6RVqsXbroj8kW1qvmkHlFAaIt4NjInYFRJn5aF06ssSsqkFn6IVmt8OqkaAhchcKY0CVdN7Fj20iQ/nlzEJO6FAASWIVCiNLHbt2rdwi6ZLiFNwuhgbHbSJAwNvjYbREzxs0OJr8dPg8RSrZQgWWniVnR8vzza0BKfTwoCEKiYwBnSpCACxEE8kVMRH0Yq7hjNQ2DbCZQoTeQYtti8mPBrGPqaG+QuYW9Rf500EQfWkp0aI3pCQRCEEnnK1dVjXg5S9zppoiSI3f0xCbMMk5Um4lxtsFqjLQ4tkZ0gDQEIVEpgkTQJF2vnk6FbhQ2lSUE8qbRfNA6BrSdQuTTxWkGwdpLCJcRFlQwFwTLSJI6N5nDSRASgoPKF0iSpRNwQWiIukIQABKolUChNwvWS5FW+cKJilkh9uFA9YbBX609abxGB6qWJkgj+fKtB7xVJSihYz4QxYjlpYgJQf+DeLvbnS2y16m+qxTA2qTUeP7tSxUNLZEWkIQCBSgnkS5OcgBNa6eNJLKNTKjKE9/AJAhAok0CJ0kSeNbGroGdv6KjOqDGfTFnMrpCXJuFV91ttoSBIhRJdVfZNH9WSfiUntUETNm3Uhu6LflHQvx9kLEy/PRhaUqZrqAsCELgQgTxpUrRHLBqS8URGp/QMStxCEgIQKJVAWdKkVKOoDAIQgMCFCeRJkwtXSgUQgMD6CSBN1s+YFiAAgSoIIE2qoE6bECiBANKkBIhUAQEI1JAA0qSGTsEkCCxDAGmyDCXKQAACzSOANGmez7AYApoA0oQHAQIQ2E4CSJPt9Cu9agEBpEkLnEwXIdBKAkiTVrqdTm8DAaTJNniRPkAAAlkCSJMsE3Ig0AgCSJNGuAkjIQCBcxNAmpwbGTdAoB4EkCb18ANWQAACZRNAmpRNlPogsCECSJMNgaYZCEBgwwSQJhsGTnMQKIsA0qQsktQDAQjUiwDSpF7+wBoILE1gRWlibuNfCEAAAhCAAAQgsA4CUsl8ID9k06b5bD45EIAABGpFgFWTWrkDYyCwPIGs0kCaLE+PkhCAQH0JIE3q6xssg8BCAkiThXi4CAEINJYA0qSxrsPwthNAmrT9CaD/ENhWAkiTbfUs/dp6AkiTrXcxHYRASwkgTVrqeLrdfAJIk+b7kB5AAAJ5BJAmeVTIg0ADCCBNGuAkTIQABFYggDRZARq3QKAOBJAmdfACNkAAAuUTQJqUz5QaIbARAmuXJvPJsNPtdbrD8VEcH036Kt3rRLON9I5GIACB9hJAmrTX9/S84QTKkibH44HWHEZ5dHujQw1GaZFomjBSZZL8WKazCGcjV0P24sKc+WRom4hj3UpKBk0jZ0NBRUeTvlBO0yjoV39ybG+TXXZ9tBf5CwEIVE2gQJqo8KLnS73OYDIXRtp5VK/jo1bsM8PC4j6SEIBAyQRKlCZ6XSRl3tGk78fz8XiQVyZ1y8U+hspDtdj3ekhVHRbIa+wwkmomLO8103wSqXUg/T8VvISayauUPAhAYNMEcqXJNPITiWnUc5ON/FF8GDn5kl9g032iPQi0gsAapYmfbXR7/ShKtnK6ZqYSrpocRskkJlksCUSMX7fwKmc2GkymyVaRm+LIZQyzNHI8HkTTYOUmlCZug8ku0kibjdoIpUl4u3tCRPxyeSQgAIFqCeRKE2mSUBuzkVgpcWXC4Z9fxhUmAQEIlEVgjdJEmVi4aiKkidIlfh6jO+aliYgdemU1WZxQqxd50x1RraooqUdWImLNbGROwKiSPi0Lp1dZlJTJWfhJ3aK7wD8QgEDFBM6UJn7VRK2VTvyudBJn8uNJxb2ieQi0gECJ0sRu36p9XCs1lpAmPjp43E6ahKHB1xZOX/wWTFjeShNz6MScQfHSJFzqcPkpneHXbGS/vKnmbK/tr8wnDQEIVErgDGkiI4CaILlZhwsjLhCZbrj8SntF4xBoAYESpYkb2AKbFxN+DUNfdoPcJcRdXlKIA2vJyTUjAs4rTbyACCSIOw2nE2YZJitNxLnaYLVGWVywjiI7QxoCEKiEwCJpEi7Wpka9/ZiKTimlUkmfaBQCrSBQuTTJPb3hQoBLpJxxfmkSJ/tBTprEfq0lqNxGpSTTl9cZwdXwFEtQCx8gAIGqCRRKE7leYowMc9wwD4d/GHaq7h3tQ2CLCVQvTZRE8OdbDWqvSFyMCH0QxggvMhbPctTV/sC9XezPl8jKUy2GsUnXYN4fRpdIaqQhUD8C+dIkJ+AkPzRg10dFGBGFU5Ghft3FIghsD4ESpYk8a2J/O+TsDR2FUo35ZG/F7Ap5aRJedb/VViRNYiV0dFU6ygT1qJaUnrC2qc9yw8htSNlMfRQuPGviDFDBy9psEu727Xk46AkEGk0gT5rY0e03c91BMX/JHbEP4k96BtVoNhgPgVoTKEua1LqTGAcBCLSQQJ40aSEGugyB5hFAmjTPZ1gMAQgsQwBpsgwlykCghgSQJjV0CiZBAAIlEECalACRKiBQBQGkSRXUaRMCEFg/AaTJ+hnTAgTWQgBpshasVAoBCFROAGlSuQswAAKrEUCarMaNuyAAgboTQJrU3UPYB4ECAkiTAjBkQwACDSeANGm4AzG/vQSQJu31PT2HwHYTQJpst3/p3RYTQJpssXPpGgRaTQBp0mr30/kmE0CaNNl72A4BCBQTQJoUs+EKBGpNAGlSa/dgHAQgsDIBpMnK6LgRAtUSWFGamNv4FwIQgAAEIAABCKyDgJRHH8gP2bRpPptPDgQgAIFaEWDVpFbuwBgILE8gqzSQJsvToyQEIFBfAkiT+voGyyCwkADSZCEeLkIAAo0lgDRprOswvO0EkCZtfwLoPwS2lQDSZFs9S7+2ngDSZOtdTAch0FICSJOWOp5uN58A0qT5PqQHEIBAHgGkSR4V8iDQAAJIkwY4CRMhAIEVCCBNVoDGLRCoAwGkSR28gA0QgED5BJAm5TOlRghshADSZCOYaQQCENg4AaTJxpHTIATKIbB2aTKfDDvdXqc7HB/F8dGkr9K9TjQrx3xqgQAEIFBAAGlSAIZsCNSdQFnS5Hg80JrDKI9ub3Soe660SDRNIKgySX4s01lGs5GrIXtxYc58MrRNxLFuJSWDppGzoaCio0lfKKdpFPSrPzlObnMyS3XZ9bGgTrIhAIGNE8iXJoeRnizpcT2YzJ1VfkTreZTNt5OrXkcWtlf5CwEIrINAidIkGM+JrUeTvh/Px+NBXplSuxUqD9Vi3+sh1VJYIK/tw0iqmbC810zTyMsRFbyEmsmrlDwIQGDTBPKkyfE48nJkGvXsZGM2Miu7sVnctaP7MHKKhGG+af/RXosJrFGa+NlGt9ePomQrp2smH+GqiZjH6DWPQMT4dQuvcmajwWSabBW5RYtg5cbWE02DlZtQmvh5UrKUIm02aiOUJuHt7rkJFJjLJQEBCFRJIE+ahPa4eYhL6Otu1LuEzp6NWB8N+fEJAmsisEZpoiwOvrOl4BDSROkSO0dJeulLypmKSKvVCzvdiUW+qFZVldQjCkhtIeZJsU/LwulVFiVlsgs/qlFnzJr8RLUQgMB5CZwlTfwiaGrUzydDPaLz48l5zaA8BCBwXgIlShN5JsNKjSWkiVhTdcY7aRKGBl9bOH3xM56wvJUm5tCJOYPip0FiqVZKkFSQ8ms2mTMlqqQ+W4MucZ4jAYH6ECiSJm5Qu3NpVoskttsg4AKRyU+Fl/p0FEsgsG0ESpQm2eWEZVZNcke7iwhqWuPPrHlxcF5p4vePnTRxwsLVbxSGjUqJp115/TlYrXHPgrrFbza5bBIQgECVBIqkibNJaRR9Siw16q1SSUUnF5dcBSQgAIG1EKhcmsgdFtdDFwJcwl0yifNLkzjZ9/FSw6+1BJWngpQvr0ulrto7/X6QzeEvBCBQMYEzpYn+OQO9xBtGAzfqXUL3JAw7FXeO5iGwzQSqlyZxuLGiYXtFUiwF7J5RHKsakhdkFs9y1NX+wL1dnK8nUi2GsUnX4N4fdg9GznEZd40EBCBQDYEzpYka7Ml6p4gG8uC8iE6pyFBNl2gVAu0gUKI0CXZekk1cfzrEH0rVYAMNocZ8snFjdoW8NInNaofb1kkkSDh98dJEyxRd2L6hE24z6Vdy3AZzrE6/OrNdSZup23Lb0omF3gB3o3tFqB2PDL2EQEMI5EgT8VKeGtFyH9ZfcqFA9dNHJ1m4IQQwEwINJVCWNGlo9zEbAhDYWgI50mRr+0rHILBVBJAmW+VOOgMBCDgCSBOHggQEmkUAadIsf2EtBCCwLAGkybKkKAeBmhFAmtTMIZgDAQiURABpUhJIqoHApgkgTTZNnPYgAIHNEECabIYzrUCgdAJIk9KRUiEEIFALAkiTWrgBIyBwfgJIk/Mz4w4IQKAJBJAmTfASNkIghwDSJAcKWRCAwBYQQJpsgRPpQjsJIE3a6Xd6DYHtJ4A02X4f08MtJYA02VLH0i0ItJ4A0qT1jwAAmkoAadJUz2E3BCCwmADSZDEfrkKgtgRWlCbmNv6FAAQgAAEIQAAC6yAgldMH8kM2bZrP5pMDAQhAoFYEWDWplTswBgLLE8gqDaTJ8vQoCQEI1JcA0qS+vsEyCCwkgDRZiIeLEIBAYwkgTRrrOgxvOwGkSdufAPoPgW0lgDTZVs/Sr60ngDTZehfTQQi0lADSpKWOp9vNJ4A0ab4P6QEEIJBHAGmSR4U8CDSAANKkAU7CRAhAYAUCSJMVoHELBOpAAGlSBy9gAwQgUD4BpEn5TKkRAhshgDTZCGYagQAENk4AabJx5DQIgXIIrF2azCfDTrfX6Q7HR3F8NOmrdK8Tzcoxn1ogAAEIFBBAmhSAIRsCdSdQljQ5Hg+05jDKo9sbHeqeKy0STRMIqkySH8t0ltFs5GrIXlyYM58MbRNxrFtJyaBp5GwoqOho0hfKaRoF/epPjtO3ab0lGk1f5zMEIFAJgXxpchjpyZIe14PJ3Fkm8uUwt5OrXkcWdneRgAAE1kCgRGmi10VSJh5N+n48H48HeWVSt1zsY6g8VIt9r4dU1WGBvMYOI6lmwvJZzXQ8HkSjM+VOXjvkQQACayWQJ02Ox5GXI9Ool6iQ9CTKRqrDyCkSpVHEpGWtllM5BFpOYI3SxM82ur1+FCVbOV0z+QhXTcR8RS8/BCLGr1t4lTMbDSbTZKuo10kWZoKVG1tPNA2CTihN9IKHmUKZZQ9pswlDoTQJb7dCJ1Wm5Y8U3YdATQjkSZPQNDcPSU+ikrXVcGjPRn4NOKyHTxCAQKkE1ihNlJ3pAW/nInJDR+kSt+ljOueliZypiLRavXCLriI/VDyqFdWiKCC1xWxkTsCoNn1aFk6vsigp47oQxzauhfGrVP9QGQQgsCqBs6RJsAiqpkB68qMSyepIfjxZ1RzugwAEliVQojSRZzKs1FhCmvg1VW+zkyZhaPC1hdMXKxHM4RJx7COnHi8jxFKtlCBZaeJ3pgMJ5W3wdfoukIIABComUCRN3EKsiBVmfmKCmA1fdm5juxGGI5vLXwhAoHQCJUoTsZzgzPRiwhxKdWXcIHcJd48sqaY1Qhm4vRsvC9RtZ0sT83KQijhORigJElZulmGy0kTEL7da40SPat/VKftAGgIQqJZAkTRxVvkFkmDb162mpKJTMOpdJSQgAIHSCVQuTXK/110IcIlUx88vTeJkW8fLCC9ogsoXShO7NyQOqXh9wxG5ACQfIFAxgTOlif45AzVjmU+GboM4trEiM+sIw07FnaN5CGwzgeqliVrz8OdbDWuvSFJCwboijBFeZCye5air/YF7u9ifL7HVqr+pFr2UURd1DZn3h8MysjLSEIBAZQTOlCZqsJvgE0QhMcxFfioyVNYrGoZACwiUKE2CnZdkE+TsDR3FWI35ZG/F7Ph4aRJedcfTiqSJ3tzRVWkDgnpUS3q1I7VBEzYttpz1Kojblk6K5S2NIE1aMFLoYvMI5EiT1HqnmBSJKOSP2AfxRxRuHgsshkCjCJQlTRrVaYyFAARaQCBHmrSg13QRAltAAGmyBU6kCxCAQA4BpEkOFLIg0AQCSJMmeAkbIQCB8xNAmpyfGXdAoBYEkCa1cANGQAACpRNAmpSOlAohsBkCSJPNcKYVCEBg0wSQJpsmTnsQKIkA0qQkkFQDAQjUjADSpGYOwRwILEsAabIsKcpBAALNIoA0aZa/sBYCjgDSxKEgAQEIbBUBpMlWuZPOtIkA0qRN3qavEGgTAaRJm7xNX7eKANJkq9xJZyAAAUcAaeJQkIBAswisKE3MbfwLAQhAAAIQgAAE1kFAyqkP5Ids2jSfzScHAhCAQK0IsGpSK3dgDASWJ5BVGkiT5elREgIQqC8BpEl9fYNlEFhIAGmyEA8XIQCBxhJAmjTWdRjedgJIk7Y/AfQfAttKAGmyrZ6lX1tPAGmy9S6mgxBoKQGkSUsdT7ebTwBp0nwf0gMIQCCPANIkjwp5EGgAAaRJA5yEiRCAwAoEkCYrQOMWCNSBANKkDl7ABghAoHwCSJPymVIjBDZCAGmyEcw0AgEIbJwA0mTjyGkQAuUQWLs0mU+GnW6v0x2Oj+L4aNJX6V4nmpVjPrVAAAIQKCCANCkAQzYE6k6gLGlyPB5ozWGUR7c3OtQ9V1okmiYQVJkkP5bpLKPZyNWQvbgwZz4Z2ibiWLeSkkHTyNlQUNHRpC+U0zQK+tWfHCe3OZmlu+zzC2olGwIQ2DCBM6TJYZRMmZRZYQQbTObeVnFJRAZ/nRQEIFA2gRKliV4XSdl3NOn7QX48HuSVSd1ysY+h8lAt9r0eUlWHBfIaO4ykmgnLC80UdC2vHvIgAIFKCSyUJrPRIBr5iFQUnRZPoirtHo1DYHsJrFGa2K0cterQj6JkK6fb6yixEg54NX1JFif0mkcQJvy6hVc5s9FgMk22inqdZGFGTG6SRZfj8SCaBis3oTQRKx9mrUXabARKKE3E7aGC2d4nhJ5BoKkEiqWJiTAyzsxGfn1X9JdhLmCQhMDGCKxRmqg+BEsLMhAIaaJ0idv0MR33JZVWsIuoIq1WL9weisgX1aqaknpEAaEt4tnInIBRJX1aFk6vsigpYxd+hJzK2G96wb8QgECVBIqkyXwy1NHDxxkdAfzWrdsUVjOTiT0ht+ouc5UIaBsCzSRQojTxA9t/VS8hTaaRFxmWoQsZodTwtYVTHD+zCctbaWI2kk248asgh5Fev0nadPlZaeJWdHy/rKHJ3xx1lSrBRwhAYNME8qWJDyMuzqQM8/u2asnWLdaG66+pe/gIAQiUSKBEaWKXE6R1Pgr4NQx93WkIl5C3uZChYoRQBm7v5rzSxLwcpNZmAgkSVm6WYbLSxE2hzNTKrdYIi/2ii8gkCQEIVEkgT5rI0OHiTNpIO19KRafUx/RdfIYABMoiULk08VpBdMmFDJcQF1VSxpc4PnvVRN1jNIeTJuKuoPKF0iSpJLghsSdPmWXKkQEBCGyMQI40CfZhk2lPdrJhpYmKTuIq0mRjrqOhthOoXpooieCWTBN3eEWSEgrWXatIE7Ot0x+4t4vzlzpSLXopo9pWsUmEqsQcdUu6C9ZS/kIAAhURyJEmgSU+zgTZ8kiZ3MSR6eAGPkAAAiUTKFGaBDsvySbI2Rs6qj/qqz3ZWzFrD0HIEFfdb7UVSRO9gqKr0gYE9aiWVHCRv2siN4zcsofN1Mdv/ftBxkJ7JjfIR5eU/FhSHQRKIHAOaRKsprhQoG3wl8L8EgykCghAIJ9AWdIkv3ZyIQABCFRF4CxpUpVdtAsBCJxBAGlyBiAuQwACDSWANGmo4zAbAkgTngEIQGA7CSBNttOv9KoFBJAmLXAyXYRAKwkgTVrpdjq9DQSQJtvgRfoAAQhkCSBNskzIgUAjCCBNGuEmjIQABM5NAGlybmTcAIF6EECa1MMPWAEBCJRNAGlSNlHqg8CGCCBNNgSaZiAAgQ0TQJpsGDjNQaAsAkiTskhSDwQgUC8CSJN6+QNrILA0AaTJ0qgoCAEINIoA0qRR7sJYCHgCSBPPghQEILBNBJAm2+RN+tIqAitKE3Mb/0IAAhCAAAQgAIF1EJBq7AP5IZs2zWfzyYEABCBQKwKsmtTKHRgDgeUJZJUG0mR5epSEAATqSwBpUl/fYBkEFhJAmizEw0UIQKCxBJAmjXUdhredANKk7U8A/YfAthJAmmyrZ+nX1hNAmmy9i+kgBFpKAGnSUsfT7eYTQJo034f0AAIQyCOANMmjQh4EGkAAadIAJ2EiBCCwAgGkyQrQuAUCdSCANKmDF7ABAhAonwDSpHym1AiBjRBAmmwEM41AAAIbJ4A02ThyGoRAOQTWLk3mk2Gn2+t0h+OjOD6a9FW614lm5ZhPLRCAAAQKCCBNCsCQDYG6EyhLmhyPB1pzGOXR7Y0Odc+VFommCQRVJsmPZTrLaDZyNWQvLsyZT4a2iTjWraRk0DRyNhRUdDTpC+U0jYJ+9SfH4jbRa3GLKEASAhCojEC+NDmM9GQpGdcuXNhJlMp3mXEciwig51eV9YaGIdAiAiVKk7xxezTpDybzhOfxeJBXplTaofJQLfa9HlIthQXy2j6MpJoJy0vNtFhd5dVMHgQgsEEChdIkO5E4mozcrENMqJRecYWDaLbBbtAUBNpHYI3SRM5C+lGUbOV0ex0lVsLvdTGP0fOVQMT4WYtXiz9u5gAACNdJREFUObPRYDJNtop6nWRhRqxhJPOe4/EgmopAk5YmboPJzpOkzSYkhdJEKJtQwbTvyaHHEKg7gVxpMp8Mw7XPbC9mI7MBHcdB4TCSZG8jBwIQKIvAGqWJMjGYZ0jBIaSJ0iVu08f0y5eUsxaRVqsXLr6IfFGtqimpRxQQ2iL2ASgWaVk4T8okCz9Kskzs0RmrbMryCvVAAAIXJ1AkTfyGjp/tiNYCCeJCjVwxFYVJQgACayBQojSRZzKs1FhCmkwjLzJsB500CaWGr202kmrGL2CE5a00MYdOzP6xXwU5jPT6TdKmy89KEx/IRKNqLcfFtSCW2U7wFwIQqJRArjSRFqnB7kZxciEVQ+LYrem6nR1ZBWkIQGANBEqUJnnnSLyY8GsYuhdu/LuE7JyTJmqmIpSB27s5rzQxLwcpwRRIkLByswyTlSbiTJybQqXMTn2UfSENAQhUQ+BMaaLfGbTzKGWjGshuOTbWGzr+rEnO+m41/aJVCGw9gcqlidcKgrWTJi4hLqrk+aWJjTJOmqjJUN40aKE0UXvP7gyKCGFIk5SD+AiB6gmcU5pkR3Eq/mQLVN9HLIDAVhKoXpooiZCzppqswTgpENJfRZokU6KBe7tYnjXx1ada9FJGFRGTKrmJI9O+JlIQgECVBM6UJmpbNpmf5MuOYLtZDfO8teEqu0jbENhOAiVKk2DnJdkEOXtDR2FVaiDZWzEjP5isiKsujhRJE78xnH3TR7Wkgov80QK5YeSCjs3UMcu/H2QslAstbhOagLWdo4NeNZtAnjRREsRGGxdPZAhKrto1UVnehYhmY8F6CNSfQFnSpP49xUIIQKBdBPKkSbsI0FsINJQA0qShjsNsCEDgDAJIkzMAcRkCdSWANKmrZ7ALAhC4GAGkycX4cTcEKiOANKkMPQ1DAAJrJYA0WSteKofA+gggTdbHlpohAIEqCSBNqqRP2xC4AAGkyQXgcSsEIFBjAkiTGjsH0yCwiADSZBEdrkEAAs0lgDRpru+wvOUEkCYtfwDoPgS2lgDSZGtdS8e2nQDSZNs9TP8g0FYCSJO2ep5+N54A0qTxLqQDEIBALgGkSS4WMiFQfwIrShNzG/9CAAIQgAAEIACBdRCQEuoD+SGbNs1n88mBAAQgUCsCrJrUyh0YA4HlCWSVBtJkeXqUhAAE6ksAaVJf32AZBBYSQJosxMNFCECgsQSQJo11HYa3nQDSpO1PAP2HwLYSQJpsq2fp19YTQJpsvYvpIARaSgBp0lLH0+3mE0CaNN+H9AACEMgjgDTJo0IeBBpAAGnSACdhIgQgsAIBpMkK0LgFAnUggDSpgxewAQIQKJ8A0qR8ptQIgY0QQJpsBDONQAACGyeANNk4chqEQDkE1i5N5pNhp9vrdIfjozg+mvRVuteJZuWYTy0QgAAECgggTQrAkA2BuhMoS5ocjwdacxjl0e2NDnXPlRaJpgkEVSbJj2U6y2g2cjVkLy7MmU+Gtok41q2kZNA0cjYUVHQ06QvlNI2CfvUnx/q2dH87qxpcYATZEIDARQkUSxMVYfSUqWdHtJg4mXmUbdxOrnqdwWRuM/kLAQislUCJ0kSvi6SMPZr0/Xg+Hg/yyqRuudjHUHmoFvteD6mqwwJ5jR1GUs2E5Qs0U6DA8uokDwIQ2DiBAmkyG4XiQ9slMuVwPoycIlEaRUxaNt4bGoRAiwisUZr42Ua314+iZCunayYf4arJYWRmMHbtIRAxft3Cq5zZaDCZJltFvU6yMBOsZOi1k+PxIJrKQJOSJupSMnkyay3SZhOGQmmSr2zmk6Gfe7Xo4aGrEKg1gVxpkj9aCyYk4fCfjfwacK07jnEQaDqBNUoThaZw1URIE6VL3KaP4emliZypiLRavXBqQOSLalVNST2igNQWYp4U+7QsnF5lUVImu/BDwGr6KMD+7SSQJ010TJi4uVAynFOj3sqX/HiynbDoFQTqRKBEaSLPZFipsYQ0mUZeZFgyTpqEocHXFqoBP+MJy1tpYg6dmHURPw0SS7VSgqSClF+zUesrtl/W0DiObRQTWSQhAIEaECiQJuIYvg0CqVFsg4ALRKYzqfBSgx5iAgS2lECJ0iS7nLDMqknuaHcRwZ9Wszs+RhycV5qYM27qXidNVPSxuznyQJyNSonDXXn9OVitsTl5Hd/Sx4VuQaBBBPKkiV8f1R1JPqZGvVUqqejk4lKDGGAqBBpJoHJp4rWC4OdCgEuIiyp5fmmilzc60cxLDb/WElSeClK+vC6Vupr6GFTEBwhAoFICedIkpTasUgmjgRv1LqH7EYadSrtG4xDYbgLVS5PYrqkK0F6RFHz3hzHCh5VU3PH16MrV1f7AvV1so5Jo2GzQyHP4YWzSNSTvDxuFxJJJiI9PEKgNgTxpEgcBxwcfEQ3kwXlfQG3dyshQm15iCAS2kECJ0kSeNbG/HeJPh/hDqZpioCHUmE/2Vsw3fSApxFW3SVwkTXTc0VXZN3RC6aBfyTGHTrQZcsPIlbSZ+kXB8KyJM0DdTajawgFBl7aIQL40MSM3CTji9Jh/X8+FAjvMTWH/huAWMaIrEKglgbKkSS07h1EQgECLCRRJkxYjoesQaAYBpEkz/ISVEIDAeQkgTc5LjPIQqAkBpElNHIEZEIBAyQSQJiUDpToIbIoA0mRTpGkHAhDYLAGkyWZ50xoESiOANCkNJRVBAAK1IoA0qZU7MAYCyxNAmizPipIQgECTCCBNmuQtbIWAIIA0ETBIQgACW0QAabJFzqQr7SKANGmXv+ktBNpDAGnSHl/T0y0jgDTZMofSHQhAICGANOFRgEBDCSBNGuo4zIYABM4ggDQ5AxCXIVBXAkiTunoGuyAAgYsRQJpcjB93Q6AyAitKE3Mb/0IAAhCAAAQgAIF1EJDK6AP5IZteR/PUCQEIQAACEIAABCQBqUDOkCayKGkIQAACEIAABCCwbgJIk3UTpn4IQAACEIAABM5BAGlyDlgUhQAEIAABCEBg3QSQJusmTP0QgAAEIAABCJyDwP8DZxCf26leOCQAAAAASUVORK5CYII="
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://discuss.pytorch.org/t/input-size-for-efficientnet-versions-from-torchvision-models/140525"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bvj4Gr16hk2O"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 이미지 변환 설정\n",
        "\n",
        "def return_transforms(model):\n",
        "    if model == inception:\n",
        "        resolution = (299,299)\n",
        "    else:\n",
        "        resolution = (224,224)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomResizedCrop(size=resolution, scale=(0.6, 1.0)),  # 더 넓은 스케일 범위\n",
        "        transforms.RandomRotation(degrees=30),  # 더 큰 회전 각도\n",
        "        # transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),  # 더 강한 컬러 증강\n",
        "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # 원근 변환 추가\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        # transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),  # 가우시안 블러 추가\n",
        "    ])\n",
        "\n",
        "\n",
        "    # train_dataset = CustomDataset(train_df, '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "    # val_dataset = CustomDataset(val_df, '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "    train_dataset = CustomDataset(train_df, 'skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "    val_dataset = CustomDataset(val_df, 'skku-2024-1-machine-learning-third-project/train', transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "여기까지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_vz2uxQh3Ct",
        "outputId": "209d6bc0-b2a3-4e53-b439-aec4ce2c6cd9"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torchvision import models\n",
        "\n",
        "# # 모델 정의\n",
        "# model = models.efficientnet_b4(pretrained=True)\n",
        "# model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(train_df['label'].unique()))\n",
        "\n",
        "# # GPU 사용 설정\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# project_name = 'b4_resoultion_changed'\n",
        "\n",
        "# model_save_path = project_name+'.pth'\n",
        "# df_save_path = './skku-2024-1-machine-learning-third-project/' + project_name + '.csv'\n",
        "# model_save_path, df_save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3JYxyL9h4oP",
        "outputId": "fa357bef-bbf6-475b-c1a3-4af137a0c4c3"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# # 학습 함수 정의\n",
        "# def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=200):\n",
        "#     best_acc = 0.0\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         running_corrects = 0\n",
        "\n",
        "#         for inputs, labels in train_loader:\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss = criterion(outputs, labels)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "#             running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
        "#         epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "#         model.eval()\n",
        "#         val_running_corrects = 0\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for inputs, labels in val_loader:\n",
        "#                 inputs = inputs.to(device)\n",
        "#                 labels = labels.to(device)\n",
        "\n",
        "#                 outputs = model(inputs)\n",
        "#                 _, preds = torch.max(outputs, 1)\n",
        "\n",
        "#                 val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "#         val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "#         print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "#         if val_acc >= best_acc:\n",
        "#             best_acc = val_acc\n",
        "#             # torch.save(model.state_dict(), '/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/best_model_200_twoaug.pth')\n",
        "#             torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "#     print('Best Val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "# # 모델 학습\n",
        "# train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NpaR43srh7I7"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "# from PIL import Image\n",
        "# from torchvision import transforms\n",
        "\n",
        "\n",
        "# # 모델 로드\n",
        "# # model.load_state_dict(torch.load('/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/best_model_200_twoaug.pth'))\n",
        "# model.load_state_dict(torch.load(model_save_path))\n",
        "# model.eval()\n",
        "\n",
        "# # 이미지 변환 설정\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize(resoultion),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# def predict_image(image_path, model):\n",
        "#     image = Image.open(image_path).convert('RGB')\n",
        "#     image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(image)\n",
        "#         _, preds = torch.max(outputs, 1)\n",
        "\n",
        "#     return preds.item()\n",
        "\n",
        "# # 예측할 이미지 리스트 생성\n",
        "# image_names = df2['image_name'].values.tolist()\n",
        "\n",
        "# # 예측 결과 저장을 위한 리스트\n",
        "# results = []\n",
        "\n",
        "# # 예측 및 결과 저장\n",
        "# for image_name in image_names:\n",
        "#     image_path = os.path.join('./skku-2024-1-machine-learning-third-project/test', image_name)\n",
        "#     predicted_class = predict_image(image_path, model)\n",
        "#     results.append({'image_name': image_name, 'label': predicted_class})\n",
        "\n",
        "# # 리스트를 데이터프레임으로 변환\n",
        "# result_df = pd.DataFrame(results)\n",
        "\n",
        "# # 결과 CSV 파일로 저장\n",
        "# # result_df.to_csv('/content/drive/MyDrive/skku-2024-1-machine-learning-third-project/predictions_200.csv', index=False)\n",
        "# result_df.to_csv(df_save_path, index=False)\n",
        "\n",
        "# print(df_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z7yXH2l_xukc"
      },
      "outputs": [],
      "source": [
        "# result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "effnet = models.efficientnet_b0(pretrained=True)\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "densenet = models.densenet121(pretrained=True)\n",
        "inception = models.inception_v3(pretrained=True)\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "\n",
        "# # Modify the models to suit our classification task\n",
        "num_classes = 6\n",
        "# dropout_rate = 0.35\n",
        "# effnet.classifier[1] = nn.Sequential(\n",
        "#             nn.Dropout(p=dropout_rate),\n",
        "#             nn.Linear(effnet.classifier[1].in_features, num_classes) \n",
        "#         )\n",
        "\n",
        "# resnet.fc = nn.Sequential(\n",
        "#             nn.Dropout(p=dropout_rate),\n",
        "#             nn.Linear(resnet.fc.in_features, num_classes) \n",
        "#         )\n",
        "\n",
        "# densenet.classifier = nn.Sequential(\n",
        "#             nn.Dropout(p=dropout_rate),\n",
        "#             nn.Linear(densenet.classifier.in_features, num_classes)  \n",
        "#         )\n",
        "\n",
        "effnet.classifier[1] = torch.nn.Linear(effnet.classifier[1].in_features, num_classes)\n",
        "resnet.fc = torch.nn.Linear(resnet.fc.in_features, num_classes)\n",
        "densenet.classifier = torch.nn.Linear(densenet.classifier.in_features, num_classes)\n",
        "inception.AuxLogits.fc = torch.nn.Linear(inception.AuxLogits.fc.in_features, num_classes)\n",
        "inception.fc = torch.nn.Linear(inception.fc.in_features, num_classes)\n",
        "mobilenet.classifier[1] = torch.nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n",
        "\n",
        "\n",
        "# class DinoClassifier(torch.nn.Module):\n",
        "#     def __init__(self, dino, num_classes):\n",
        "#         super(DinoClassifier, self).__init__()\n",
        "#         self.dino = dino\n",
        "#         self.fc = torch.nn.Linear(dino.embed_dim, num_classes)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = self.dino(x)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# dino_classifier = DinoClassifier(dino, num_classes)\n",
        "\n",
        "# Set up the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "effnet.to(device)\n",
        "resnet.to(device)\n",
        "densenet.to(device)\n",
        "inception.to(device)\n",
        "mobilenet.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_acc_max = 0\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_acc, model, model_name):\n",
        "        score = val_acc\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_acc, model, model_name)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_acc, model, model_name)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_acc, model, model_name):\n",
        "        '''Saves model when validation accuracy increase.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
        "        if model_name == 'effnet':\n",
        "            print(f'current model:{model_name}')\n",
        "            torch.save(model.state_dict(), './skku-2024-1-machine-learning-third-project/models/eff'+ trial +'.pth')\n",
        "        elif model_name == 'resnet':\n",
        "            print(f'current model:{model_name}')\n",
        "            torch.save(model.state_dict(), './skku-2024-1-machine-learning-third-project/models/res'+ trial +'.pth')\n",
        "        elif model_name == 'densenet':\n",
        "            print(f'current model:{model_name}')\n",
        "            torch.save(model.state_dict(), './skku-2024-1-machine-learning-third-project/models/den'+ trial +'.pth')\n",
        "        elif model_name == 'inception':\n",
        "            print(f'current model:{model_name}')\n",
        "            torch.save(model.state_dict(), './skku-2024-1-machine-learning-third-project/models/inc'+ trial +'.pth')\n",
        "        elif model_name == 'mobilenet':\n",
        "            print(f'current model:{model_name}')\n",
        "            torch.save(model.state_dict(), './skku-2024-1-machine-learning-third-project/models/mob'+ trial +'.pth')\n",
        "        else:\n",
        "            print(\"=============Model Wrong Save=================\")\n",
        "        self.val_acc_max = val_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Loss: 0.6495, Acc: 0.7619, Val Acc: 0.8362\n",
            "Epoch 2/100, Loss: 0.4125, Acc: 0.8524, Val Acc: 0.8547\n",
            "Epoch 3/100, Loss: 0.3561, Acc: 0.8722, Val Acc: 0.8798\n",
            "Epoch 4/100, Loss: 0.3488, Acc: 0.8722, Val Acc: 0.8520\n",
            "Epoch 5/100, Loss: 0.3345, Acc: 0.8831, Val Acc: 0.8758\n",
            "Epoch 6/100, Loss: 0.2782, Acc: 0.9003, Val Acc: 0.8613\n",
            "Epoch 7/100, Loss: 0.2555, Acc: 0.9079, Val Acc: 0.8732\n",
            "Epoch 8/100, Loss: 0.2314, Acc: 0.9122, Val Acc: 0.8705\n",
            "Epoch 9/100, Loss: 0.2312, Acc: 0.9174, Val Acc: 0.8613\n",
            "Epoch 10/100, Loss: 0.2141, Acc: 0.9240, Val Acc: 0.8771\n",
            "Epoch 11/100, Loss: 0.2102, Acc: 0.9214, Val Acc: 0.8732\n",
            "Epoch 12/100, Loss: 0.1967, Acc: 0.9343, Val Acc: 0.8719\n",
            "Epoch 13/100, Loss: 0.1959, Acc: 0.9323, Val Acc: 0.8626\n",
            "Epoch 14/100, Loss: 0.1796, Acc: 0.9320, Val Acc: 0.8719\n",
            "Epoch 15/100, Loss: 0.1680, Acc: 0.9422, Val Acc: 0.8719\n",
            "Epoch 16/100, Loss: 0.1516, Acc: 0.9472, Val Acc: 0.8745\n",
            "Epoch 17/100, Loss: 0.1399, Acc: 0.9485, Val Acc: 0.8758\n",
            "Validation accuracy increased (0.000000 --> 0.875826).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 18/100, Loss: 0.1578, Acc: 0.9445, Val Acc: 0.8626\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 19/100, Loss: 0.1414, Acc: 0.9495, Val Acc: 0.8798\n",
            "Validation accuracy increased (0.875826 --> 0.879789).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 20/100, Loss: 0.1407, Acc: 0.9478, Val Acc: 0.8811\n",
            "Validation accuracy increased (0.879789 --> 0.881110).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 21/100, Loss: 0.1245, Acc: 0.9561, Val Acc: 0.8732\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 22/100, Loss: 0.1367, Acc: 0.9485, Val Acc: 0.8692\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Epoch 23/100, Loss: 0.1198, Acc: 0.9600, Val Acc: 0.8600\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Epoch 24/100, Loss: 0.1062, Acc: 0.9604, Val Acc: 0.8758\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Epoch 25/100, Loss: 0.1279, Acc: 0.9531, Val Acc: 0.8560\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Epoch 26/100, Loss: 0.0935, Acc: 0.9683, Val Acc: 0.8666\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Epoch 27/100, Loss: 0.1023, Acc: 0.9637, Val Acc: 0.8811\n",
            "Validation accuracy increased (0.881110 --> 0.881110).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 28/100, Loss: 0.1268, Acc: 0.9515, Val Acc: 0.8758\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 29/100, Loss: 0.0950, Acc: 0.9693, Val Acc: 0.8838\n",
            "Validation accuracy increased (0.881110 --> 0.883752).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 30/100, Loss: 0.0944, Acc: 0.9680, Val Acc: 0.8692\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 31/100, Loss: 0.0797, Acc: 0.9746, Val Acc: 0.8838\n",
            "Validation accuracy increased (0.883752 --> 0.883752).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 32/100, Loss: 0.0957, Acc: 0.9686, Val Acc: 0.8719\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 33/100, Loss: 0.0947, Acc: 0.9673, Val Acc: 0.8838\n",
            "Validation accuracy increased (0.883752 --> 0.883752).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 34/100, Loss: 0.0869, Acc: 0.9693, Val Acc: 0.8824\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 35/100, Loss: 0.1037, Acc: 0.9647, Val Acc: 0.8613\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Epoch 36/100, Loss: 0.0826, Acc: 0.9703, Val Acc: 0.8745\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Epoch 37/100, Loss: 0.0921, Acc: 0.9680, Val Acc: 0.8824\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Epoch 38/100, Loss: 0.0717, Acc: 0.9766, Val Acc: 0.8666\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Epoch 39/100, Loss: 0.0803, Acc: 0.9706, Val Acc: 0.8877\n",
            "Validation accuracy increased (0.883752 --> 0.887715).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 40/100, Loss: 0.0923, Acc: 0.9683, Val Acc: 0.8758\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 41/100, Loss: 0.1051, Acc: 0.9647, Val Acc: 0.8851\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Epoch 42/100, Loss: 0.0885, Acc: 0.9676, Val Acc: 0.8851\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Epoch 43/100, Loss: 0.0659, Acc: 0.9802, Val Acc: 0.8758\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Epoch 44/100, Loss: 0.0684, Acc: 0.9766, Val Acc: 0.8732\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Epoch 45/100, Loss: 0.0546, Acc: 0.9805, Val Acc: 0.8877\n",
            "Validation accuracy increased (0.887715 --> 0.887715).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 46/100, Loss: 0.0663, Acc: 0.9772, Val Acc: 0.8719\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 47/100, Loss: 0.0674, Acc: 0.9779, Val Acc: 0.8613\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Epoch 48/100, Loss: 0.0661, Acc: 0.9799, Val Acc: 0.8758\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Epoch 49/100, Loss: 0.0577, Acc: 0.9802, Val Acc: 0.8798\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Epoch 50/100, Loss: 0.0718, Acc: 0.9756, Val Acc: 0.8719\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Epoch 51/100, Loss: 0.0616, Acc: 0.9789, Val Acc: 0.8864\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Epoch 52/100, Loss: 0.0917, Acc: 0.9686, Val Acc: 0.8811\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Epoch 53/100, Loss: 0.0749, Acc: 0.9719, Val Acc: 0.8877\n",
            "Validation accuracy increased (0.887715 --> 0.887715).  Saving model ...\n",
            "current model:mobilenet\n",
            "Epoch 54/100, Loss: 0.0664, Acc: 0.9752, Val Acc: 0.8626\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Epoch 55/100, Loss: 0.0690, Acc: 0.9782, Val Acc: 0.8639\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Epoch 56/100, Loss: 0.0582, Acc: 0.9808, Val Acc: 0.8613\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Epoch 57/100, Loss: 0.0449, Acc: 0.9832, Val Acc: 0.8798\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Epoch 58/100, Loss: 0.0598, Acc: 0.9769, Val Acc: 0.8719\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Epoch 59/100, Loss: 0.0599, Acc: 0.9785, Val Acc: 0.8771\n",
            "EarlyStopping counter: 6 out of 20\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# Initialize wandb\n",
        "# wandb.init(project=\"Third Project\")\n",
        "# wandb.run.name = 'ensemble' + trial\n",
        "# wandb.run.name = 'mobilenet'\n",
        "# wandb.run.save()\n",
        "\n",
        "def train_model(model, criterion, optimizer, model_name, num_epochs=100, patience=20):\n",
        "    best_acc = 0.0\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        train_loader, val_loader = return_transforms(model)\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_running_corrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch+1 }/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "        # wandb.log({\"epoch\": epoch + 1, \"loss\": epoch_loss, \"Accuracy\": epoch_acc, \"Val Acc\": val_acc})\n",
        "\n",
        "        if epoch >15: \n",
        "            early_stopping(val_acc, model, model_name)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    print('Best Val Acc: {:4f}'.format(early_stopping.val_acc_max))\n",
        "    if model_name == 'effnet':\n",
        "        model.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/eff'+ trial +'.pth'))\n",
        "    elif model_name == 'resnet':\n",
        "        model.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/res'+ trial +'.pth'))\n",
        "    elif model_name == 'densenet':\n",
        "        model.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/den'+ trial +'.pth'))\n",
        "    elif model_name == 'inception':\n",
        "        model.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/inc'+ trial +'.pth'))\n",
        "    elif model_name == 'mobilenet':\n",
        "        model.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/mob'+ trial +'.pth'))\n",
        "    return model\n",
        "\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer_effnet = torch.optim.Adam(effnet.parameters(), lr=1e-4)\n",
        "optimizer_resnet = torch.optim.Adam(resnet.parameters(), lr=1e-4)\n",
        "optimizer_densenet = torch.optim.Adam(densenet.parameters(), lr=1e-4)\n",
        "optimizer_inception = torch.optim.Adam(inception.parameters(), lr=1e-4)\n",
        "optimizer_mobilenet = torch.optim.Adam(mobilenet.parameters(), lr=1e-4)\n",
        "optimizer_convnext = torch.optim.Adam(convnext.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "\n",
        "# inception = train_model(inception, criterion, optimizer_inception, 'inception',1)\n",
        "mobilenet = train_model(mobilenet, criterion, optimizer_mobilenet, 'mobilenet')\n",
        "# convnext = train_model(convnext, criterion, optimizer_convnext, 'convnext',1)\n",
        "# effnet = train_model(effnet, train_loader, criterion, optimizer_effnet, 'effnet')\n",
        "# resnet = train_model(resnet, train_loader, criterion, optimizer_resnet, 'resnet')\n",
        "# densenet = train_model(densenet, train_loader, criterion, optimizer_densenet, 'densenet')\n",
        "\n",
        "# Finish the wandb run\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'efficientnet_b1'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m effnet_v2 \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mefficientnet_b1(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m      3\u001b[0m effnet_v2\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(effnet_v2\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39min_features, num_classes)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'efficientnet_b1'"
          ]
        }
      ],
      "source": [
        "effnet_v2 = models.efficientnet_b1(pretrained=False)\n",
        "num_classes = 6\n",
        "effnet_v2.classifier[1] = torch.nn.Linear(effnet_v2.classifier[1].in_features, num_classes)\n",
        "effnet_v2.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/eff6.pth'))\n",
        "effnet_v2.eval() \n",
        "effnet_v2.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model Validation Accuracy with Soft Voting: 88.64%\n"
          ]
        }
      ],
      "source": [
        "# Function to get soft voting ensemble predictions\n",
        "def soft_voting_ensemble_predict(models, inputs):\n",
        "    outputs = [torch.nn.functional.softmax(model(inputs), dim=1) for model in models]\n",
        "    avg_output = sum(outputs) / len(outputs)\n",
        "    return avg_output\n",
        "\n",
        "# Evaluate the ensemble model using soft voting\n",
        "# models = [effnet, resnet, densenet, inception, mobilenet]\n",
        "models = [effnet_v2]\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for inputs, labels in val_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = soft_voting_ensemble_predict(models, inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Ensemble Model Validation Accuracy with Soft Voting: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# 디바이스 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # 모델 로드 함수\n",
        "# def load_model(model_path):\n",
        "#     model.load_state_dict(torch.load(model_path))\n",
        "#     model = model.to(device)\n",
        "#     model.eval()\n",
        "#     return model\n",
        "\n",
        "# model_paths = [\n",
        "#     './skku-2024-1-machine-learning-third-project/models/eff.pth',\n",
        "#     './skku-2024-1-machine-learning-third-project/models/res.pth',\n",
        "#     './skku-2024-1-machine-learning-third-project/models/den.pth'\n",
        "# ]\n",
        "\n",
        "\n",
        "# effnet_b2.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/eff.pth'))\n",
        "# effnet_b2 = effnet_b2.to(device)\n",
        "# effnet_b2.eval()\n",
        "\n",
        "# resnet50.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/eff.pth'))\n",
        "# resnet50 = resnet50.to(device)\n",
        "# resnet50.eval()\n",
        "\n",
        "# densenet.load_state_dict(torch.load('./skku-2024-1-machine-learning-third-project/models/eff.pth'))\n",
        "# densenet = densenet.to(device)\n",
        "# densenet.eval()\n",
        "\n",
        "models = [effnet, resnet, densenet, inception, mobilenet]\n",
        "\n",
        "# 이미지 변환 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(resolution),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def soft_voting_ensemble_predict(models, image):\n",
        "    outputs = [torch.nn.functional.softmax(model(image), dim=1) for model in models]\n",
        "    avg_output = sum(outputs) / len(outputs)\n",
        "    return avg_output\n",
        "\n",
        "def predict_image(image_path, models):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = soft_voting_ensemble_predict(models, image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    return preds.item()\n",
        "\n",
        "# 예측할 이미지 리스트 생성\n",
        "image_names = df2['image_name'].values.tolist()\n",
        "\n",
        "# 예측 결과 저장을 위한 리스트\n",
        "results = []\n",
        "\n",
        "# 예측 및 결과 저장\n",
        "for image_name in image_names:\n",
        "    image_path = os.path.join('./skku-2024-1-machine-learning-third-project/test', image_name)\n",
        "    predicted_class = predict_image(image_path, models)\n",
        "    results.append({'image_name': image_name, 'label': predicted_class})\n",
        "\n",
        "# 리스트를 데이터프레임으로 변환\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "# # 결과 CSV 파일로 저장\n",
        "# result_df.to_csv('./skku-2024-1-machine-learning-third-project/ensemble_effb0resdense.csv', index=False)\n",
        "\n",
        "# print('./skku-2024-1-machine-learning-third-project/ensemble_effb0resdense.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6417.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6418.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6420.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6422.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6425.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>7132.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>7134.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>7135.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>7136.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>7138.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    image_name  label\n",
              "0     6417.jpg      0\n",
              "1     6418.jpg      3\n",
              "2     6420.jpg      0\n",
              "3     6422.jpg      2\n",
              "4     6425.jpg      5\n",
              "..         ...    ...\n",
              "435   7132.jpg      5\n",
              "436   7134.jpg      4\n",
              "437   7135.jpg      1\n",
              "438   7136.jpg      4\n",
              "439   7138.jpg      0\n",
              "\n",
              "[440 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./skku-2024-1-machine-learning-third-project/ensemble_final_7th.csv\n"
          ]
        }
      ],
      "source": [
        "result_df.to_csv('./skku-2024-1-machine-learning-third-project/ensemble_final_' + trial + 'th.csv', index=False)\n",
        "\n",
        "print('./skku-2024-1-machine-learning-third-project/ensemble_final_' + trial + 'th.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Convnext 실험"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ben81\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import convnext_tiny\n",
        "convnext = convnext_tiny(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvNeXt(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
              "      )\n",
              "      (3): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
              "      )\n",
              "      (4): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
              "      )\n",
              "      (5): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
              "      )\n",
              "      (6): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
              "      )\n",
              "      (7): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
              "      )\n",
              "      (8): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=768, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convnext.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "effnet.classifier[1] = torch.nn.Linear(effnet.classifier[1].in_features, num_classes)\n",
        "resnet.fc = torch.nn.Linear(resnet.fc.in_features, num_classes)\n",
        "densenet.classifier = torch.nn.Linear(densenet.classifier.in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvNeXt(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
              "      )\n",
              "      (3): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
              "      )\n",
              "      (4): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
              "      )\n",
              "      (5): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
              "      )\n",
              "      (6): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
              "      )\n",
              "      (7): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
              "      )\n",
              "      (8): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate='none')\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=768, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convnext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "convnext.classifier[2] = torch.nn.Linear(convnext.classifier[2].in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
