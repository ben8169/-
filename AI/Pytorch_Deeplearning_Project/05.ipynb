{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjw7rTG77i5o",
        "outputId": "12b7ad75-61b8-4cf3-ebce-57f65df5cda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'fonts-nanum-extra' for glob 'fonts-nanum*'\n",
            "Note, selecting 'fonts-nanum-coding' for glob 'fonts-nanum*'\n",
            "Note, selecting 'fonts-nanum-eco' for glob 'fonts-nanum*'\n",
            "Note, selecting 'fonts-nanum' for glob 'fonts-nanum*'\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum fonts-nanum-coding fonts-nanum-eco fonts-nanum-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 46.0 MB of archives.\n",
            "After this operation, 177 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum-coding all 2.5-3 [4,988 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum-eco all 1.000-7 [14.7 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum-extra all 20200506-1 [21.0 MB]\n",
            "Fetched 46.0 MB in 6s (8,280 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Selecting previously unselected package fonts-nanum-coding.\n",
            "Preparing to unpack .../fonts-nanum-coding_2.5-3_all.deb ...\n",
            "Unpacking fonts-nanum-coding (2.5-3) ...\n",
            "Selecting previously unselected package fonts-nanum-eco.\n",
            "Preparing to unpack .../fonts-nanum-eco_1.000-7_all.deb ...\n",
            "Unpacking fonts-nanum-eco (1.000-7) ...\n",
            "Selecting previously unselected package fonts-nanum-extra.\n",
            "Preparing to unpack .../fonts-nanum-extra_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum-extra (20200506-1) ...\n",
            "Setting up fonts-nanum-extra (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum-coding (2.5-3) ...\n",
            "Setting up fonts-nanum-eco (1.000-7) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 39 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum*\n",
        "!sudo fc-cache -fv\n",
        "!rm -rf ~/.cache/matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtU0r_A57u45",
        "outputId": "297b45e9-9e31-4716-9017-35d1e00bad58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torchviz-0.0.2\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wELsqGW_79YT"
      },
      "outputs": [],
      "source": [
        "# https://github.com/wikibook/pytorchdl2/blob/main/notebooks/ch05_regression.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0RGXzjiX7vX4"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# 폰트 관련 용도\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchviz import make_dot\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SITWzkn9tSRu"
      },
      "source": [
        "#### 1입력 1출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a3jkDb9rg2u",
        "outputId": "86634438-113b-4b1d-f273-c943fa71fcaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=1, out_features=1, bias=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "l1 = nn.Linear(1, 1)\n",
        "\n",
        "print(l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ68ZA_Srh-J",
        "outputId": "f10d46c4-1543-4107-95be-5d64e2b2083a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name:  weight\n",
            "tensor:  Parameter containing:\n",
            "tensor([[-0.4078]], requires_grad=True)\n",
            "shape:  torch.Size([1, 1])\n",
            "name:  bias\n",
            "tensor:  Parameter containing:\n",
            "tensor([0.0331], requires_grad=True)\n",
            "shape:  torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "for param in l1.named_parameters():\n",
        "    print('name: ', param[0])\n",
        "    print('tensor: ', param[1])\n",
        "    print('shape: ', param[1].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Xc3lQ5r3z8",
        "outputId": "73875349-70a1-4c11-8d8a-cb47fbb8930d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[2.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "#명시적 초기화\n",
        "nn.init.constant_(l1.weight, 2.0)\n",
        "nn.init.constant_(l1.bias, 1.0)\n",
        "\n",
        "print(l1.weight)\n",
        "print(l1.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urnk_jtasgvx",
        "outputId": "3603b90b-716c-428a-9469-58614ccd9ba6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 1]),\n",
              " tensor([[-2.],\n",
              "         [-1.],\n",
              "         [ 0.],\n",
              "         [ 1.],\n",
              "         [ 2.]]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_np = np.arange(-2,2.1,1)\n",
        "x = torch.tensor(x_np, dtype = torch.float32)\n",
        "x = x.view(-1,1)\n",
        "x.shape, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjs1l8qntA-f",
        "outputId": "ed64698d-aa62-4bd2-ad9a-79f8e94022c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 1]),\n",
              " tensor([[-3.],\n",
              "         [-1.],\n",
              "         [ 1.],\n",
              "         [ 3.],\n",
              "         [ 5.]]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = l1(x)\n",
        "y.shape, y.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUyJ3fPntUGX"
      },
      "source": [
        "2입력 1출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd9hsOu7tNOR",
        "outputId": "54df03cd-63cd-49e1-985c-821965127692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[1., 1.]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([2.], requires_grad=True))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l2 = nn.Linear(2, 1)\n",
        "nn.init.constant_(l2.weight, 1.)\n",
        "nn.init.constant_(l2.bias, 2.)\n",
        "l2.weight, l2.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzK7cCtUtiJz",
        "outputId": "473b2f0d-78ff-4d39-9919-11a2b795a622"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 2]),\n",
              " tensor([[0., 0.],\n",
              "         [0., 1.],\n",
              "         [1., 0.],\n",
              "         [1., 1.]]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2 = torch.tensor([[0, 0],\n",
        "                   [0, 1],\n",
        "                   [1, 0],\n",
        "                   [1, 1]], dtype = torch.float32)\n",
        "\n",
        "x2.shape, x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erBWgg8xtxyG",
        "outputId": "309e4650-80dd-440d-a1cc-c645ce3ac3e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 1]),\n",
              " tensor([[2.],\n",
              "         [3.],\n",
              "         [3.],\n",
              "         [4.]]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y2 = l2(x2)\n",
        "y2.shape, y2.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qmr2l8IuDbJ"
      },
      "source": [
        "2입력 3출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-oAlqNCt0QN",
        "outputId": "a9769c28-390e-47b3-943c-cc1635aed814"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[1., 1.],\n",
              "         [2., 2.],\n",
              "         [3., 3.]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([2., 2., 2.], requires_grad=True))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l3 = nn.Linear(2,3)\n",
        "\n",
        "nn.init.constant_(l3.weight[0,:], 1.0)\n",
        "nn.init.constant_(l3.weight[1,0:2], 2.0)\n",
        "nn.init.constant_(l3.weight[2,:], 3.0)\n",
        "nn.init.constant_(l3.bias, 2.0)\n",
        "\n",
        "l3.weight, l3.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgeKDlrSuVrb",
        "outputId": "deb8bbf4-7dcc-459c-c52e-99b0d3b3e2df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 3]),\n",
              " tensor([[2., 2., 2.],\n",
              "         [3., 4., 5.],\n",
              "         [3., 4., 5.],\n",
              "         [4., 6., 8.]]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y3 = l3(x2)\n",
        "y3.shape, y3.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQQT8fTXvfKt"
      },
      "source": [
        "### 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wJjmY5YBu94J"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        return x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DQGs5RSwQBb",
        "outputId": "7f1cdc4c-f6e2-443d-d902-fc63d299dd3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([100, 1])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.ones(100,1)\n",
        "\n",
        "n_input = 1\n",
        "n_output = 1\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "outputs = net(inputs)\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GCqD6wOswZH3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(outputs, labels) / 2.\n",
        "\n",
        "loss.backward()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
