{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- -----------\n",
      "altgraph            0.17.2\n",
      "appnope             0.1.4\n",
      "asttokens           2.4.1\n",
      "beautifulsoup4      4.12.3\n",
      "blinker             1.7.0\n",
      "certifi             2024.2.2\n",
      "charset-normalizer  3.3.2\n",
      "click               8.1.7\n",
      "comm                0.2.1\n",
      "contourpy           1.2.0\n",
      "cycler              0.12.1\n",
      "debugpy             1.8.1\n",
      "decorator           5.1.1\n",
      "exceptiongroup      1.2.0\n",
      "executing           2.0.1\n",
      "filelock            3.13.1\n",
      "Flask               3.0.2\n",
      "fonttools           4.49.0\n",
      "fsspec              2024.2.0\n",
      "future              0.18.2\n",
      "idna                3.6\n",
      "importlib-metadata  7.0.1\n",
      "importlib_resources 6.1.2\n",
      "ipykernel           6.29.3\n",
      "ipython             8.18.1\n",
      "itsdangerous        2.1.2\n",
      "jedi                0.19.1\n",
      "Jinja2              3.1.3\n",
      "joblib              1.3.2\n",
      "jupyter_client      8.6.0\n",
      "jupyter_core        5.7.1\n",
      "kiwisolver          1.4.5\n",
      "macholib            1.15.2\n",
      "MarkupSafe          2.1.5\n",
      "matplotlib          3.8.3\n",
      "matplotlib-inline   0.1.6\n",
      "mpmath              1.3.0\n",
      "nest-asyncio        1.6.0\n",
      "networkx            3.2.1\n",
      "numpy               1.26.4\n",
      "packaging           23.2\n",
      "pandas              2.2.1\n",
      "parso               0.8.3\n",
      "pexpect             4.9.0\n",
      "pillow              10.2.0\n",
      "pip                 24.0\n",
      "platformdirs        4.2.0\n",
      "prompt-toolkit      3.0.43\n",
      "psutil              5.9.8\n",
      "ptyprocess          0.7.0\n",
      "pure-eval           0.2.2\n",
      "Pygments            2.17.2\n",
      "pyparsing           3.1.1\n",
      "python-dateutil     2.9.0.post0\n",
      "pytz                2024.1\n",
      "pyzmq               25.1.2\n",
      "requests            2.31.0\n",
      "scikit-learn        1.4.1.post1\n",
      "scipy               1.12.0\n",
      "setuptools          58.0.4\n",
      "six                 1.15.0\n",
      "soupsieve           2.5\n",
      "stack-data          0.6.3\n",
      "sympy               1.12\n",
      "threadpoolctl       3.3.0\n",
      "torch               2.2.1\n",
      "torchvision         0.17.1\n",
      "tornado             6.4\n",
      "traitlets           5.14.1\n",
      "typing_extensions   4.10.0\n",
      "tzdata              2024.1\n",
      "urllib3             2.2.1\n",
      "wcwidth             0.2.13\n",
      "Werkzeug            3.0.1\n",
      "wheel               0.37.0\n",
      "zipp                3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Machine Learning 기본 프로세스\n",
    "1. Hypothesis 설정 -> 데이터를 가장 잘 표현할 수 있는 함수 H(x) 설정\n",
    "2. Cost Function 설정 -> Hypothesis의 결과와 label간의 차이를 평가할 수 있는 함수 설정\n",
    "3. Learning Algorithm 설계 -> <b>Cost가 최소가 되도록 H(x)의 파라미터를 조정하는 것</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Perceptron\n",
    ">>##### Single Perceptron 구성\n",
    " - Activation Function = Step f, Sigmoid, ReLU 등, sum(wx+b)을 입력받아 정해진 출력을 내보내는 함수\n",
    "\n",
    "$S=X\\cdot W + b= \\begin{bmatrix}x_{1}&x_{2}&x_{3}\\end{bmatrix}\\begin{bmatrix}w_{1}\\\\w_{2}\\\\w_{3}\\end{bmatrix} + b = x_{1}w_{1} + x_{2}w_{2} + x_{3}w_{3} + b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 10 18 28 40]\n",
      "103\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "W = np.array([4, 5, 6, 7, 8])\n",
    "B = 3\n",
    "\n",
    "print(X*W) # 각자의 원소끼리 곱해짐\n",
    "print(np.sum(W*X) + B) # 각자의 원소끼리 곱한 후 모두 더해짐\n",
    "print(np.matmul(W, X) + B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Linear Regression\n",
    "- Activation func \"f(x)=x\" 사용... H(x) = wx + b\n",
    "> Cost Function : Mean Squared Error (MSE)\n",
    "> $(1/m)*\\sum_{i=1}^{n}(h(x_{i})-y_{i})^{2}$\n",
    "- Cost func: label과 예측값 간의 차이(Error)를 수치화 하기 위한 함수.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Activation(x):\n",
    "    return W*x + B\n",
    "\n",
    "def Cost():\n",
    "    return np.mean((Activation(X) - Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.5\n",
      "1198.5\n",
      "0 0 177.0\n",
      "0 1 154.0\n",
      "0 2 133.0\n",
      "0 3 114.0\n",
      "0 4 97.0\n",
      "0 5 82.0\n",
      "0 6 69.0\n",
      "0 7 58.0\n",
      "0 8 49.0\n",
      "0 9 42.0\n",
      "1 0 50.5\n",
      "1 1 38.5\n",
      "1 2 28.5\n",
      "1 3 20.5\n",
      "1 4 14.5\n",
      "1 5 10.5\n",
      "1 6 8.5\n",
      "1 7 8.5\n",
      "1 8 10.5\n",
      "1 9 14.5\n",
      "2 0 1.0\n",
      "2 1 0.0\n",
      "2 2 1.0\n",
      "2 3 4.0\n",
      "2 4 9.0\n",
      "2 5 16.0\n",
      "2 6 25.0\n",
      "2 7 36.0\n",
      "2 8 49.0\n",
      "2 9 64.0\n",
      "3 0 28.5\n",
      "3 1 38.5\n",
      "3 2 50.5\n",
      "3 3 64.5\n",
      "3 4 80.5\n",
      "3 5 98.5\n",
      "3 6 118.5\n",
      "3 7 140.5\n",
      "3 8 164.5\n",
      "3 9 190.5\n",
      "4 0 133.0\n",
      "4 1 154.0\n",
      "4 2 177.0\n",
      "4 3 202.0\n",
      "4 4 229.0\n",
      "4 5 258.0\n",
      "4 6 289.0\n",
      "4 7 322.0\n",
      "4 8 357.0\n",
      "4 9 394.0\n",
      "5 0 314.5\n",
      "5 1 346.5\n",
      "5 2 380.5\n",
      "5 3 416.5\n",
      "5 4 454.5\n",
      "5 5 494.5\n",
      "5 6 536.5\n",
      "5 7 580.5\n",
      "5 8 626.5\n",
      "5 9 674.5\n",
      "6 0 573.0\n",
      "6 1 616.0\n",
      "6 2 661.0\n",
      "6 3 708.0\n",
      "6 4 757.0\n",
      "6 5 808.0\n",
      "6 6 861.0\n",
      "6 7 916.0\n",
      "6 8 973.0\n",
      "6 9 1032.0\n",
      "7 0 908.5\n",
      "7 1 962.5\n",
      "7 2 1018.5\n",
      "7 3 1076.5\n",
      "7 4 1136.5\n",
      "7 5 1198.5\n",
      "7 6 1262.5\n",
      "7 7 1328.5\n",
      "7 8 1396.5\n",
      "7 9 1466.5\n",
      "8 0 1321.0\n",
      "8 1 1386.0\n",
      "8 2 1453.0\n",
      "8 3 1522.0\n",
      "8 4 1593.0\n",
      "8 5 1666.0\n",
      "8 6 1741.0\n",
      "8 7 1818.0\n",
      "8 8 1897.0\n",
      "8 9 1978.0\n",
      "9 0 1810.5\n",
      "9 1 1886.5\n",
      "9 2 1964.5\n",
      "9 3 2044.5\n",
      "9 4 2126.5\n",
      "9 5 2210.5\n",
      "9 6 2296.5\n",
      "9 7 2384.5\n",
      "9 8 2474.5\n",
      "9 9 2566.5\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,3,4,5,6,7,8,9,10], dtype=np.float32)\n",
    "Y = np.array([3,5,7,9,11,13,15,17,19,21], dtype=np.float32)\n",
    "\n",
    "W = 3\n",
    "B = 1\n",
    "print(Cost())\n",
    "\n",
    "W = 7\n",
    "B = 5\n",
    "print(Cost())\n",
    "\n",
    "for W in range(10):\n",
    "    for B in range(10):\n",
    "        print(W, B, Cost())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Gradient Descent Algorithm(경사하강법)\n",
    "- Cost Function의 기울기가 최저가 되도록..\n",
    "\n",
    "> Gradient -> partial derivative<br>\n",
    "> $\\frac{\\partial}{\\partial w}cost(w, b) = \\frac{1}{m}  \\sum_{i=1}^{m}(x_{i}(x_{i}w+(b-y_{i})))$\n",
    "<br>\n",
    "> $\\frac{\\partial}{\\partial b}cost(w, b) = \\frac{1}{m}  \\sum_{i=1}^{m}(x_{i}w - y_{i} + b)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([1,2,3,4,5,6,7,8,9,10], dtype=np.float32)\n",
    "labels = np.array([3,5,7,9,11,13,15,17,19,21], dtype=np.float32)\n",
    "\n",
    "W, B = np.random.normal(), np.random.normal()\n",
    "\n",
    "def Hypothesis(x):\n",
    "    return W*x + B\n",
    "\n",
    "def Cost():\n",
    "    return np.mean((Hypothesis(x_input) - labels)**2)\n",
    "\n",
    "def Gradient(x, y):\n",
    "    return np.mean(x*(x*W + (B-y))), np.mean((W*x-y+B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 W = -0.282, B = 0.597 Cost = 210.673\n",
      " 1000 W = 2.009, B = 0.941 Cost = 0.001\n",
      " 2000 W = 2.007, B = 0.952 Cost = 0.000\n",
      " 3000 W = 2.006, B = 0.961 Cost = 0.000\n",
      " 4000 W = 2.005, B = 0.968 Cost = 0.000\n",
      " 5000 W = 2.004, B = 0.974 Cost = 0.000\n",
      " 6000 W = 2.003, B = 0.979 Cost = 0.000\n",
      " 7000 W = 2.002, B = 0.983 Cost = 0.000\n",
      " 8000 W = 2.002, B = 0.986 Cost = 0.000\n",
      " 9000 W = 2.002, B = 0.989 Cost = 0.000\n",
      "10000 W = 2.001, B = 0.991 Cost = 0.000\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "for cnt in range(0, epochs+1):\n",
    "    if cnt%(epochs//10) == 0:\n",
    "        print(f\"{cnt:5} W = {W:.3f}, B = {B:.3f} Cost = {Cost():.3f}\")\n",
    "    \n",
    "    grad_w, grad_b = Gradient(x_input, labels)\n",
    "    W-=learning_rate*grad_w\n",
    "    B-=learning_rate*grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient 미분을 어떻게 할까?\n",
    "1. math 모듈 등을 이용해 편미분한다.\n",
    "2. 수학적으로 편미분된 결과를 대입해서 return 한다.\n",
    "3. 순간변화율 == 평균변화율로 근사하여 구한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regression 필기](./img/Regression.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#편미분 대신 평균변화율을 이용함\n",
    "def Gradient(x, y):\n",
    "    global W, B\n",
    "    pres_w, pres_b = W, B\n",
    "    delta = 5e-7\n",
    "\n",
    "    W = pres_w + delta\n",
    "    cost_p = Cost()\n",
    "    W = pres_w - delta\n",
    "    cost_m = Cost()\n",
    "    grad_w = (cost_p - cost_m)/(2*delta)\n",
    "    W = pres_w\n",
    "\n",
    "    B = pres_b + delta\n",
    "    cost_p = Cost()\n",
    "    B = pres_b - delta\n",
    "    cost_m = Cost()\n",
    "    grad_b = (cost_p - cost_m)/(2*delta)\n",
    "    B = pres_b\n",
    "\n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Self test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([23, 29, 35, 41, 47, 53, 59, 65, 71], dtype = np.float32)\n",
    "labels = np.array([120.0, 120.0, 120.0, 121.0, 122.0, 124.0, 126.0, 128.0, 130.0], dtype = np.float32)\n",
    "\n",
    "W = np.random.normal()\n",
    "B = np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hypothesis(x):\n",
    "    return W*x + B\n",
    "\n",
    "def Cost():\n",
    "    return np.mean((Hypothesis(x_input) - labels)**2)\n",
    "\n",
    "def Gradient(x, y):\n",
    "    return np.mean(x*(x*W+(B-y))), np.mean((W*x-y+B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:   500, w:    2.3934, b:  -0.13927, cost:    1258.5\n",
      "epochs:  1000, w:    2.3933, b:   -0.1365, cost:    1258.4\n",
      "epochs:  1500, w:    2.3932, b:  -0.13372, cost:    1258.3\n",
      "epochs:  2000, w:    2.3932, b:  -0.13095, cost:    1258.3\n",
      "epochs:  2500, w:    2.3931, b:  -0.12817, cost:    1258.2\n",
      "epochs:  3000, w:    2.3931, b:   -0.1254, cost:    1258.2\n",
      "epochs:  3500, w:     2.393, b:  -0.12263, cost:    1258.1\n",
      "epochs:  4000, w:     2.393, b:  -0.11985, cost:    1258.0\n",
      "epochs:  4500, w:    2.3929, b:  -0.11708, cost:    1258.0\n",
      "epochs:  5000, w:    2.3929, b:  -0.11431, cost:    1257.9\n",
      "epochs:  5500, w:    2.3928, b:  -0.11153, cost:    1257.9\n",
      "epochs:  6000, w:    2.3928, b:  -0.10876, cost:    1257.8\n",
      "epochs:  6500, w:    2.3927, b:  -0.10599, cost:    1257.7\n",
      "epochs:  7000, w:    2.3927, b:  -0.10321, cost:    1257.7\n",
      "epochs:  7500, w:    2.3926, b:  -0.10044, cost:    1257.6\n",
      "epochs:  8000, w:    2.3926, b: -0.097667, cost:    1257.5\n",
      "epochs:  8500, w:    2.3925, b: -0.094894, cost:    1257.5\n",
      "epochs:  9000, w:    2.3924, b: -0.092121, cost:    1257.4\n",
      "epochs:  9500, w:    2.3924, b: -0.089348, cost:    1257.4\n",
      "epochs: 10000, w:    2.3923, b: -0.086575, cost:    1257.3\n",
      "epochs: 10500, w:    2.3923, b: -0.083802, cost:    1257.2\n",
      "epochs: 11000, w:    2.3922, b:  -0.08103, cost:    1257.2\n",
      "epochs: 11500, w:    2.3922, b: -0.078257, cost:    1257.1\n",
      "epochs: 12000, w:    2.3921, b: -0.075485, cost:    1257.1\n",
      "epochs: 12500, w:    2.3921, b: -0.072712, cost:    1257.0\n",
      "epochs: 13000, w:     2.392, b:  -0.06994, cost:    1256.9\n",
      "epochs: 13500, w:     2.392, b: -0.067167, cost:    1256.9\n",
      "epochs: 14000, w:    2.3919, b: -0.064395, cost:    1256.8\n",
      "epochs: 14500, w:    2.3919, b: -0.061623, cost:    1256.7\n",
      "epochs: 15000, w:    2.3918, b: -0.058851, cost:    1256.7\n",
      "epochs: 15500, w:    2.3918, b: -0.056079, cost:    1256.6\n",
      "epochs: 16000, w:    2.3917, b: -0.053307, cost:    1256.6\n",
      "epochs: 16500, w:    2.3916, b: -0.050535, cost:    1256.5\n",
      "epochs: 17000, w:    2.3916, b: -0.047763, cost:    1256.4\n",
      "epochs: 17500, w:    2.3915, b: -0.044991, cost:    1256.4\n",
      "epochs: 18000, w:    2.3915, b: -0.042219, cost:    1256.3\n",
      "epochs: 18500, w:    2.3914, b: -0.039448, cost:    1256.3\n",
      "epochs: 19000, w:    2.3914, b: -0.036676, cost:    1256.2\n",
      "epochs: 19500, w:    2.3913, b: -0.033905, cost:    1256.1\n",
      "epochs: 20000, w:    2.3913, b: -0.031133, cost:    1256.1\n",
      "epochs: 20500, w:    2.3912, b: -0.028362, cost:    1256.0\n",
      "epochs: 21000, w:    2.3912, b:  -0.02559, cost:    1255.9\n",
      "epochs: 21500, w:    2.3911, b: -0.022819, cost:    1255.9\n",
      "epochs: 22000, w:    2.3911, b: -0.020048, cost:    1255.8\n",
      "epochs: 22500, w:     2.391, b: -0.017277, cost:    1255.8\n",
      "epochs: 23000, w:     2.391, b: -0.014506, cost:    1255.7\n",
      "epochs: 23500, w:    2.3909, b: -0.011735, cost:    1255.6\n",
      "epochs: 24000, w:    2.3908, b: -0.008964, cost:    1255.6\n",
      "epochs: 24500, w:    2.3908, b:-0.0061932, cost:    1255.5\n",
      "epochs: 25000, w:    2.3907, b:-0.0034224, cost:    1255.5\n",
      "epochs: 25500, w:    2.3907, b:-0.00065169, cost:    1255.4\n",
      "epochs: 26000, w:    2.3906, b:  0.002119, cost:    1255.3\n",
      "epochs: 26500, w:    2.3906, b: 0.0048895, cost:    1255.3\n",
      "epochs: 27000, w:    2.3905, b:   0.00766, cost:    1255.2\n",
      "epochs: 27500, w:    2.3905, b:   0.01043, cost:    1255.1\n",
      "epochs: 28000, w:    2.3904, b:  0.013201, cost:    1255.1\n",
      "epochs: 28500, w:    2.3904, b:  0.015971, cost:    1255.0\n",
      "epochs: 29000, w:    2.3903, b:  0.018741, cost:    1255.0\n",
      "epochs: 29500, w:    2.3903, b:  0.021512, cost:    1254.9\n",
      "epochs: 30000, w:    2.3902, b:  0.024282, cost:    1254.8\n",
      "epochs: 30500, w:    2.3902, b:  0.027052, cost:    1254.8\n",
      "epochs: 31000, w:    2.3901, b:  0.029822, cost:    1254.7\n",
      "epochs: 31500, w:    2.3901, b:  0.032591, cost:    1254.7\n",
      "epochs: 32000, w:      2.39, b:  0.035361, cost:    1254.6\n",
      "epochs: 32500, w:    2.3899, b:  0.038131, cost:    1254.5\n",
      "epochs: 33000, w:    2.3899, b:  0.040901, cost:    1254.5\n",
      "epochs: 33500, w:    2.3898, b:   0.04367, cost:    1254.4\n",
      "epochs: 34000, w:    2.3898, b:   0.04644, cost:    1254.3\n",
      "epochs: 34500, w:    2.3897, b:  0.049209, cost:    1254.3\n",
      "epochs: 35000, w:    2.3897, b:  0.051979, cost:    1254.2\n",
      "epochs: 35500, w:    2.3896, b:  0.054748, cost:    1254.2\n",
      "epochs: 36000, w:    2.3896, b:  0.057517, cost:    1254.1\n",
      "epochs: 36500, w:    2.3895, b:  0.060287, cost:    1254.0\n",
      "epochs: 37000, w:    2.3895, b:  0.063056, cost:    1254.0\n",
      "epochs: 37500, w:    2.3894, b:  0.065825, cost:    1253.9\n",
      "epochs: 38000, w:    2.3894, b:  0.068594, cost:    1253.9\n",
      "epochs: 38500, w:    2.3893, b:  0.071363, cost:    1253.8\n",
      "epochs: 39000, w:    2.3893, b:  0.074132, cost:    1253.7\n",
      "epochs: 39500, w:    2.3892, b:  0.076901, cost:    1253.7\n",
      "epochs: 40000, w:    2.3891, b:  0.079669, cost:    1253.6\n",
      "epochs: 40500, w:    2.3891, b:  0.082438, cost:    1253.6\n",
      "epochs: 41000, w:     2.389, b:  0.085207, cost:    1253.5\n",
      "epochs: 41500, w:     2.389, b:  0.087975, cost:    1253.4\n",
      "epochs: 42000, w:    2.3889, b:  0.090744, cost:    1253.4\n",
      "epochs: 42500, w:    2.3889, b:  0.093512, cost:    1253.3\n",
      "epochs: 43000, w:    2.3888, b:   0.09628, cost:    1253.2\n",
      "epochs: 43500, w:    2.3888, b:  0.099049, cost:    1253.2\n",
      "epochs: 44000, w:    2.3887, b:   0.10182, cost:    1253.1\n",
      "epochs: 44500, w:    2.3887, b:   0.10458, cost:    1253.1\n",
      "epochs: 45000, w:    2.3886, b:   0.10735, cost:    1253.0\n",
      "epochs: 45500, w:    2.3886, b:   0.11012, cost:    1252.9\n",
      "epochs: 46000, w:    2.3885, b:   0.11289, cost:    1252.9\n",
      "epochs: 46500, w:    2.3885, b:   0.11566, cost:    1252.8\n",
      "epochs: 47000, w:    2.3884, b:   0.11842, cost:    1252.8\n",
      "epochs: 47500, w:    2.3884, b:   0.12119, cost:    1252.7\n",
      "epochs: 48000, w:    2.3883, b:   0.12396, cost:    1252.6\n",
      "epochs: 48500, w:    2.3882, b:   0.12673, cost:    1252.6\n",
      "epochs: 49000, w:    2.3882, b:   0.12949, cost:    1252.5\n",
      "epochs: 49500, w:    2.3881, b:   0.13226, cost:    1252.4\n",
      "epochs: 50000, w:    2.3881, b:   0.13503, cost:    1252.4\n",
      "epochs: 50500, w:     2.388, b:    0.1378, cost:    1252.3\n",
      "epochs: 51000, w:     2.388, b:   0.14056, cost:    1252.3\n",
      "epochs: 51500, w:    2.3879, b:   0.14333, cost:    1252.2\n",
      "epochs: 52000, w:    2.3879, b:    0.1461, cost:    1252.1\n",
      "epochs: 52500, w:    2.3878, b:   0.14887, cost:    1252.1\n",
      "epochs: 53000, w:    2.3878, b:   0.15163, cost:    1252.0\n",
      "epochs: 53500, w:    2.3877, b:    0.1544, cost:    1252.0\n",
      "epochs: 54000, w:    2.3877, b:   0.15717, cost:    1251.9\n",
      "epochs: 54500, w:    2.3876, b:   0.15993, cost:    1251.8\n",
      "epochs: 55000, w:    2.3876, b:    0.1627, cost:    1251.8\n",
      "epochs: 55500, w:    2.3875, b:   0.16547, cost:    1251.7\n",
      "epochs: 56000, w:    2.3874, b:   0.16823, cost:    1251.7\n",
      "epochs: 56500, w:    2.3874, b:     0.171, cost:    1251.6\n",
      "epochs: 57000, w:    2.3873, b:   0.17377, cost:    1251.5\n",
      "epochs: 57500, w:    2.3873, b:   0.17653, cost:    1251.5\n",
      "epochs: 58000, w:    2.3872, b:    0.1793, cost:    1251.4\n",
      "epochs: 58500, w:    2.3872, b:   0.18206, cost:    1251.3\n",
      "epochs: 59000, w:    2.3871, b:   0.18483, cost:    1251.3\n",
      "epochs: 59500, w:    2.3871, b:    0.1876, cost:    1251.2\n",
      "epochs: 60000, w:     2.387, b:   0.19036, cost:    1251.2\n",
      "epochs: 60500, w:     2.387, b:   0.19313, cost:    1251.1\n",
      "epochs: 61000, w:    2.3869, b:    0.1959, cost:    1251.0\n",
      "epochs: 61500, w:    2.3869, b:   0.19866, cost:    1251.0\n",
      "epochs: 62000, w:    2.3868, b:   0.20143, cost:    1250.9\n",
      "epochs: 62500, w:    2.3868, b:   0.20419, cost:    1250.9\n",
      "epochs: 63000, w:    2.3867, b:   0.20696, cost:    1250.8\n",
      "epochs: 63500, w:    2.3867, b:   0.20972, cost:    1250.7\n",
      "epochs: 64000, w:    2.3866, b:   0.21249, cost:    1250.7\n",
      "epochs: 64500, w:    2.3865, b:   0.21525, cost:    1250.6\n",
      "epochs: 65000, w:    2.3865, b:   0.21802, cost:    1250.5\n",
      "epochs: 65500, w:    2.3864, b:   0.22078, cost:    1250.5\n",
      "epochs: 66000, w:    2.3864, b:   0.22355, cost:    1250.4\n",
      "epochs: 66500, w:    2.3863, b:   0.22632, cost:    1250.4\n",
      "epochs: 67000, w:    2.3863, b:   0.22908, cost:    1250.3\n",
      "epochs: 67500, w:    2.3862, b:   0.23185, cost:    1250.2\n",
      "epochs: 68000, w:    2.3862, b:   0.23461, cost:    1250.2\n",
      "epochs: 68500, w:    2.3861, b:   0.23738, cost:    1250.1\n",
      "epochs: 69000, w:    2.3861, b:   0.24014, cost:    1250.1\n",
      "epochs: 69500, w:     2.386, b:    0.2429, cost:    1250.0\n",
      "epochs: 70000, w:     2.386, b:   0.24567, cost:    1249.9\n",
      "epochs: 70500, w:    2.3859, b:   0.24843, cost:    1249.9\n",
      "epochs: 71000, w:    2.3859, b:    0.2512, cost:    1249.8\n",
      "epochs: 71500, w:    2.3858, b:   0.25396, cost:    1249.8\n",
      "epochs: 72000, w:    2.3857, b:   0.25673, cost:    1249.7\n",
      "epochs: 72500, w:    2.3857, b:   0.25949, cost:    1249.6\n",
      "epochs: 73000, w:    2.3856, b:   0.26226, cost:    1249.6\n",
      "epochs: 73500, w:    2.3856, b:   0.26502, cost:    1249.5\n",
      "epochs: 74000, w:    2.3855, b:   0.26778, cost:    1249.4\n",
      "epochs: 74500, w:    2.3855, b:   0.27055, cost:    1249.4\n",
      "epochs: 75000, w:    2.3854, b:   0.27331, cost:    1249.3\n",
      "epochs: 75500, w:    2.3854, b:   0.27608, cost:    1249.3\n",
      "epochs: 76000, w:    2.3853, b:   0.27884, cost:    1249.2\n",
      "epochs: 76500, w:    2.3853, b:    0.2816, cost:    1249.1\n",
      "epochs: 77000, w:    2.3852, b:   0.28437, cost:    1249.1\n",
      "epochs: 77500, w:    2.3852, b:   0.28713, cost:    1249.0\n",
      "epochs: 78000, w:    2.3851, b:    0.2899, cost:    1249.0\n",
      "epochs: 78500, w:    2.3851, b:   0.29266, cost:    1248.9\n",
      "epochs: 79000, w:     2.385, b:   0.29542, cost:    1248.8\n",
      "epochs: 79500, w:     2.385, b:   0.29819, cost:    1248.8\n",
      "epochs: 80000, w:    2.3849, b:   0.30095, cost:    1248.7\n",
      "epochs: 80500, w:    2.3848, b:   0.30371, cost:    1248.7\n",
      "epochs: 81000, w:    2.3848, b:   0.30648, cost:    1248.6\n",
      "epochs: 81500, w:    2.3847, b:   0.30924, cost:    1248.5\n",
      "epochs: 82000, w:    2.3847, b:     0.312, cost:    1248.5\n",
      "epochs: 82500, w:    2.3846, b:   0.31476, cost:    1248.4\n",
      "epochs: 83000, w:    2.3846, b:   0.31753, cost:    1248.3\n",
      "epochs: 83500, w:    2.3845, b:   0.32029, cost:    1248.3\n",
      "epochs: 84000, w:    2.3845, b:   0.32305, cost:    1248.2\n",
      "epochs: 84500, w:    2.3844, b:   0.32582, cost:    1248.2\n",
      "epochs: 85000, w:    2.3844, b:   0.32858, cost:    1248.1\n",
      "epochs: 85500, w:    2.3843, b:   0.33134, cost:    1248.0\n",
      "epochs: 86000, w:    2.3843, b:    0.3341, cost:    1248.0\n",
      "epochs: 86500, w:    2.3842, b:   0.33687, cost:    1247.9\n",
      "epochs: 87000, w:    2.3842, b:   0.33963, cost:    1247.9\n",
      "epochs: 87500, w:    2.3841, b:   0.34239, cost:    1247.8\n",
      "epochs: 88000, w:    2.3841, b:   0.34515, cost:    1247.7\n",
      "epochs: 88500, w:     2.384, b:   0.34791, cost:    1247.7\n",
      "epochs: 89000, w:    2.3839, b:   0.35068, cost:    1247.6\n",
      "epochs: 89500, w:    2.3839, b:   0.35344, cost:    1247.6\n",
      "epochs: 90000, w:    2.3838, b:    0.3562, cost:    1247.5\n",
      "epochs: 90500, w:    2.3838, b:   0.35896, cost:    1247.4\n",
      "epochs: 91000, w:    2.3837, b:   0.36172, cost:    1247.4\n",
      "epochs: 91500, w:    2.3837, b:   0.36449, cost:    1247.3\n",
      "epochs: 92000, w:    2.3836, b:   0.36725, cost:    1247.2\n",
      "epochs: 92500, w:    2.3836, b:   0.37001, cost:    1247.2\n",
      "epochs: 93000, w:    2.3835, b:   0.37277, cost:    1247.1\n",
      "epochs: 93500, w:    2.3835, b:   0.37553, cost:    1247.1\n",
      "epochs: 94000, w:    2.3834, b:   0.37829, cost:    1247.0\n",
      "epochs: 94500, w:    2.3834, b:   0.38106, cost:    1246.9\n",
      "epochs: 95000, w:    2.3833, b:   0.38382, cost:    1246.9\n",
      "epochs: 95500, w:    2.3833, b:   0.38658, cost:    1246.8\n",
      "epochs: 96000, w:    2.3832, b:   0.38934, cost:    1246.8\n",
      "epochs: 96500, w:    2.3832, b:    0.3921, cost:    1246.7\n",
      "epochs: 97000, w:    2.3831, b:   0.39486, cost:    1246.6\n",
      "epochs: 97500, w:     2.383, b:   0.39762, cost:    1246.6\n",
      "epochs: 98000, w:     2.383, b:   0.40038, cost:    1246.5\n",
      "epochs: 98500, w:    2.3829, b:   0.40314, cost:    1246.5\n",
      "epochs: 99000, w:    2.3829, b:    0.4059, cost:    1246.4\n",
      "epochs: 99500, w:    2.3828, b:   0.40867, cost:    1246.3\n",
      "epochs:100000, w:    2.3828, b:   0.41143, cost:    1246.3\n",
      "epochs:100500, w:    2.3827, b:   0.41419, cost:    1246.2\n",
      "epochs:101000, w:    2.3827, b:   0.41695, cost:    1246.2\n",
      "epochs:101500, w:    2.3826, b:   0.41971, cost:    1246.1\n",
      "epochs:102000, w:    2.3826, b:   0.42247, cost:    1246.0\n",
      "epochs:102500, w:    2.3825, b:   0.42523, cost:    1246.0\n",
      "epochs:103000, w:    2.3825, b:   0.42799, cost:    1245.9\n",
      "epochs:103500, w:    2.3824, b:   0.43075, cost:    1245.8\n",
      "epochs:104000, w:    2.3824, b:   0.43351, cost:    1245.8\n",
      "epochs:104500, w:    2.3823, b:   0.43627, cost:    1245.7\n",
      "epochs:105000, w:    2.3823, b:   0.43903, cost:    1245.7\n",
      "epochs:105500, w:    2.3822, b:   0.44179, cost:    1245.6\n",
      "epochs:106000, w:    2.3821, b:   0.44455, cost:    1245.5\n",
      "epochs:106500, w:    2.3821, b:   0.44731, cost:    1245.5\n",
      "epochs:107000, w:     2.382, b:   0.45007, cost:    1245.4\n",
      "epochs:107500, w:     2.382, b:   0.45283, cost:    1245.4\n",
      "epochs:108000, w:    2.3819, b:   0.45559, cost:    1245.3\n",
      "epochs:108500, w:    2.3819, b:   0.45835, cost:    1245.2\n",
      "epochs:109000, w:    2.3818, b:   0.46111, cost:    1245.2\n",
      "epochs:109500, w:    2.3818, b:   0.46386, cost:    1245.1\n",
      "epochs:110000, w:    2.3817, b:   0.46662, cost:    1245.1\n",
      "epochs:110500, w:    2.3817, b:   0.46938, cost:    1245.0\n",
      "epochs:111000, w:    2.3816, b:   0.47214, cost:    1244.9\n",
      "epochs:111500, w:    2.3816, b:    0.4749, cost:    1244.9\n",
      "epochs:112000, w:    2.3815, b:   0.47766, cost:    1244.8\n",
      "epochs:112500, w:    2.3815, b:   0.48042, cost:    1244.7\n",
      "epochs:113000, w:    2.3814, b:   0.48318, cost:    1244.7\n",
      "epochs:113500, w:    2.3814, b:   0.48594, cost:    1244.6\n",
      "epochs:114000, w:    2.3813, b:    0.4887, cost:    1244.6\n",
      "epochs:114500, w:    2.3812, b:   0.49145, cost:    1244.5\n",
      "epochs:115000, w:    2.3812, b:   0.49421, cost:    1244.4\n",
      "epochs:115500, w:    2.3811, b:   0.49697, cost:    1244.4\n",
      "epochs:116000, w:    2.3811, b:   0.49973, cost:    1244.3\n",
      "epochs:116500, w:     2.381, b:   0.50249, cost:    1244.3\n",
      "epochs:117000, w:     2.381, b:   0.50525, cost:    1244.2\n",
      "epochs:117500, w:    2.3809, b:     0.508, cost:    1244.1\n",
      "epochs:118000, w:    2.3809, b:   0.51076, cost:    1244.1\n",
      "epochs:118500, w:    2.3808, b:   0.51352, cost:    1244.0\n",
      "epochs:119000, w:    2.3808, b:   0.51628, cost:    1244.0\n",
      "epochs:119500, w:    2.3807, b:   0.51904, cost:    1243.9\n",
      "epochs:120000, w:    2.3807, b:    0.5218, cost:    1243.8\n",
      "epochs:120500, w:    2.3806, b:   0.52455, cost:    1243.8\n",
      "epochs:121000, w:    2.3806, b:   0.52731, cost:    1243.7\n",
      "epochs:121500, w:    2.3805, b:   0.53007, cost:    1243.7\n",
      "epochs:122000, w:    2.3805, b:   0.53283, cost:    1243.6\n",
      "epochs:122500, w:    2.3804, b:   0.53558, cost:    1243.5\n",
      "epochs:123000, w:    2.3803, b:   0.53834, cost:    1243.5\n",
      "epochs:123500, w:    2.3803, b:    0.5411, cost:    1243.4\n",
      "epochs:124000, w:    2.3802, b:   0.54386, cost:    1243.3\n",
      "epochs:124500, w:    2.3802, b:   0.54661, cost:    1243.3\n",
      "epochs:125000, w:    2.3801, b:   0.54937, cost:    1243.2\n",
      "epochs:125500, w:    2.3801, b:   0.55213, cost:    1243.2\n",
      "epochs:126000, w:      2.38, b:   0.55488, cost:    1243.1\n",
      "epochs:126500, w:      2.38, b:   0.55764, cost:    1243.0\n",
      "epochs:127000, w:    2.3799, b:    0.5604, cost:    1243.0\n",
      "epochs:127500, w:    2.3799, b:   0.56316, cost:    1242.9\n",
      "epochs:128000, w:    2.3798, b:   0.56591, cost:    1242.9\n",
      "epochs:128500, w:    2.3798, b:   0.56867, cost:    1242.8\n",
      "epochs:129000, w:    2.3797, b:   0.57143, cost:    1242.7\n",
      "epochs:129500, w:    2.3797, b:   0.57418, cost:    1242.7\n",
      "epochs:130000, w:    2.3796, b:   0.57694, cost:    1242.6\n",
      "epochs:130500, w:    2.3796, b:    0.5797, cost:    1242.6\n",
      "epochs:131000, w:    2.3795, b:   0.58245, cost:    1242.5\n",
      "epochs:131500, w:    2.3794, b:   0.58521, cost:    1242.4\n",
      "epochs:132000, w:    2.3794, b:   0.58796, cost:    1242.4\n",
      "epochs:132500, w:    2.3793, b:   0.59072, cost:    1242.3\n",
      "epochs:133000, w:    2.3793, b:   0.59348, cost:    1242.3\n",
      "epochs:133500, w:    2.3792, b:   0.59623, cost:    1242.2\n",
      "epochs:134000, w:    2.3792, b:   0.59899, cost:    1242.1\n",
      "epochs:134500, w:    2.3791, b:   0.60175, cost:    1242.1\n",
      "epochs:135000, w:    2.3791, b:    0.6045, cost:    1242.0\n",
      "epochs:135500, w:     2.379, b:   0.60726, cost:    1242.0\n",
      "epochs:136000, w:     2.379, b:   0.61001, cost:    1241.9\n",
      "epochs:136500, w:    2.3789, b:   0.61277, cost:    1241.8\n",
      "epochs:137000, w:    2.3789, b:   0.61552, cost:    1241.8\n",
      "epochs:137500, w:    2.3788, b:   0.61828, cost:    1241.7\n",
      "epochs:138000, w:    2.3788, b:   0.62103, cost:    1241.6\n",
      "epochs:138500, w:    2.3787, b:   0.62379, cost:    1241.6\n",
      "epochs:139000, w:    2.3787, b:   0.62655, cost:    1241.5\n",
      "epochs:139500, w:    2.3786, b:    0.6293, cost:    1241.5\n",
      "epochs:140000, w:    2.3785, b:   0.63206, cost:    1241.4\n",
      "epochs:140500, w:    2.3785, b:   0.63481, cost:    1241.3\n",
      "epochs:141000, w:    2.3784, b:   0.63757, cost:    1241.3\n",
      "epochs:141500, w:    2.3784, b:   0.64032, cost:    1241.2\n",
      "epochs:142000, w:    2.3783, b:   0.64308, cost:    1241.2\n",
      "epochs:142500, w:    2.3783, b:   0.64583, cost:    1241.1\n",
      "epochs:143000, w:    2.3782, b:   0.64859, cost:    1241.0\n",
      "epochs:143500, w:    2.3782, b:   0.65134, cost:    1241.0\n",
      "epochs:144000, w:    2.3781, b:    0.6541, cost:    1240.9\n",
      "epochs:144500, w:    2.3781, b:   0.65685, cost:    1240.9\n",
      "epochs:145000, w:     2.378, b:    0.6596, cost:    1240.8\n",
      "epochs:145500, w:     2.378, b:   0.66236, cost:    1240.7\n",
      "epochs:146000, w:    2.3779, b:   0.66511, cost:    1240.7\n",
      "epochs:146500, w:    2.3779, b:   0.66787, cost:    1240.6\n",
      "epochs:147000, w:    2.3778, b:   0.67062, cost:    1240.6\n",
      "epochs:147500, w:    2.3778, b:   0.67338, cost:    1240.5\n",
      "epochs:148000, w:    2.3777, b:   0.67613, cost:    1240.4\n",
      "epochs:148500, w:    2.3776, b:   0.67888, cost:    1240.4\n",
      "epochs:149000, w:    2.3776, b:   0.68164, cost:    1240.3\n",
      "epochs:149500, w:    2.3775, b:   0.68439, cost:    1240.2\n",
      "epochs:150000, w:    2.3775, b:   0.68715, cost:    1240.2\n",
      "CPU times: user 1.73 s, sys: 3.4 ms, total: 1.73 s\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 150000\n",
    "learning_rate = 5e-7\n",
    "\n",
    "for i in range(1,epochs+1):\n",
    "    if (i%500==0):\n",
    "        print(\"epochs:{:>6}, w:{:>10.5}, b:{:>10.5}, cost:{:10.5}\".format(i, W, B, Cost()))\n",
    "\n",
    "    grad_w, grad_b = Gradient(x_input, labels)\n",
    "    W -= learning_rate*grad_w\n",
    "    B -= learning_rate*grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.56160727769418\n"
     ]
    }
   ],
   "source": [
    "def predict(x):\n",
    "    print(Hypothesis(x))\n",
    "\n",
    "predict(50.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Multi Variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:174\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Real\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPngImagePlugin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2)\n",
      "(18, 1)\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array([[25,21.6],[25,23.5],[25,26],[35,22.5],[35,24.6],[35,26.8],[45,22.6],[45,24.4],[45,26.4],[55,22.5],[55,24.3],[55,26.1],[65,22.2],[65,24.1],[65,25.9],[75,21.0],[75,23.0],[75,25.0]], dtype= np.float32)\n",
    "labels = np.array([[110],[120],[130],[114],[120],[130],[114],[121],[130],[116],[125],[133],[119],[128],[137],[120],[130],[139]], dtype= np.float32)\n",
    "print(x_input.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "W = np.random.normal(size=(2, 1))\n",
    "B = np.random.normal(size=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hypothesis(X):\n",
    "    return np.matmul(X, W) + B\n",
    "\n",
    "def Cost():\n",
    "    return np.mean((Hypothesis(x_input)-labels)**2)\n",
    "\n",
    "def Gradient():\n",
    "    global W, B\n",
    "    pres_w = W.copy()\n",
    "    grad_w = np.zeros_like(W)\n",
    "    pres_b = B.copy()\n",
    "    grad_b = np.zeros_like(B)\n",
    "    delta = 5e-7\n",
    "\n",
    "    for idx_r in range(W.shape[0]):\n",
    "        for idx_c in range(W.shape[1]):\n",
    "            W[idx_r, idx_c] = pres_w[idx_r, idx_c] + delta\n",
    "            cost_p = Cost()\n",
    "            W[idx_r, idx_c] = pres_w[idx_r, idx_c] - delta\n",
    "            cost_m = Cost()\n",
    "            grad_w[idx_r, idx_c] = (cost_p-cost_m)/(2*delta)\n",
    "            W[idx_r, idx_c] = pres_w[idx_r, idx_c]\n",
    "        \n",
    "    pres_b = B\n",
    "    B = pres_b + delta\n",
    "    cost_p = Cost()\n",
    "    B = pres_b - delta\n",
    "    cost_m = Cost()\n",
    "    grad_B = (cost_p-cost_m)/(2*delta)\n",
    "    B = pres_b\n",
    "\n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0] W:0.73641/3.4708, B:1.7221, Cost:80.376\n",
      "[    500] W:0.72378/3.4997, B:1.7221, Cost:76.406\n",
      "[   1000] W:0.7115/3.5277, B:1.7221, Cost:72.653\n",
      "[   1500] W:0.69957/3.555, B:1.7221, Cost:69.107\n",
      "[   2000] W:0.68796/3.5815, B:1.7221, Cost:65.756\n",
      "[   2500] W:0.67668/3.6073, B:1.7221, Cost:62.588\n",
      "[   3000] W:0.66572/3.6323, B:1.7221, Cost:59.595\n",
      "[   3500] W:0.65506/3.6567, B:1.7221, Cost:56.766\n",
      "[   4000] W:0.64469/3.6804, B:1.7221, Cost:54.092\n",
      "[   4500] W:0.63462/3.7034, B:1.7221, Cost:51.566\n",
      "[   5000] W:0.62482/3.7258, B:1.7221, Cost:49.178\n",
      "[   5500] W:0.6153/3.7476, B:1.7221, Cost:46.921\n",
      "[   6000] W:0.60604/3.7687, B:1.7221, Cost:44.789\n",
      "[   6500] W:0.59704/3.7893, B:1.7221, Cost:42.773\n",
      "[   7000] W:0.58829/3.8093, B:1.7221, Cost:40.868\n",
      "[   7500] W:0.57979/3.8287, B:1.7221, Cost:39.068\n",
      "[   8000] W:0.57152/3.8476, B:1.7221, Cost:37.367\n",
      "[   8500] W:0.56348/3.866, B:1.7221, Cost:35.759\n",
      "[   9000] W:0.55567/3.8838, B:1.7221, Cost:34.239\n",
      "[   9500] W:0.54808/3.9012, B:1.7221, Cost:32.803\n",
      "[  10000] W:0.54069/3.9181, B:1.7221, Cost:31.446\n",
      "[  10500] W:0.53351/3.9345, B:1.7221, Cost:30.164\n",
      "[  11000] W:0.52653/3.9504, B:1.7221, Cost:28.952\n",
      "[  11500] W:0.51975/3.9659, B:1.7221, Cost:27.806\n",
      "[  12000] W:0.51315/3.981, B:1.7221, Cost:26.724\n",
      "[  12500] W:0.50674/3.9956, B:1.7221, Cost: 25.7\n",
      "[  13000] W:0.50051/4.0099, B:1.7221, Cost:24.733\n",
      "[  13500] W:0.49445/4.0237, B:1.7221, Cost:23.82\n",
      "[  14000] W:0.48856/4.0372, B:1.7221, Cost:22.956\n",
      "[  14500] W:0.48283/4.0503, B:1.7221, Cost:22.14\n",
      "[  15000] W:0.47727/4.063, B:1.7221, Cost:21.369\n",
      "[  15500] W:0.47186/4.0754, B:1.7221, Cost:20.64\n",
      "[  16000] W:0.46659/4.0874, B:1.7221, Cost:19.951\n",
      "[  16500] W:0.46148/4.0991, B:1.7221, Cost: 19.3\n",
      "[  17000] W:0.45651/4.1104, B:1.7221, Cost:18.684\n",
      "[  17500] W:0.45167/4.1215, B:1.7221, Cost:18.103\n",
      "[  18000] W:0.44698/4.1322, B:1.7221, Cost:17.553\n",
      "[  18500] W:0.44241/4.1426, B:1.7221, Cost:17.034\n",
      "[  19000] W:0.43797/4.1528, B:1.7221, Cost:16.543\n",
      "[  19500] W:0.43365/4.1627, B:1.7221, Cost:16.079\n",
      "[  20000] W:0.42945/4.1722, B:1.7221, Cost:15.641\n",
      "[  20500] W:0.42537/4.1816, B:1.7221, Cost:15.227\n",
      "[  21000] W:0.42141/4.1906, B:1.7221, Cost:14.835\n",
      "[  21500] W:0.41755/4.1994, B:1.7221, Cost:14.465\n",
      "[  22000] W:0.4138/4.208, B:1.7221, Cost:14.115\n",
      "[  22500] W:0.41016/4.2163, B:1.7221, Cost:13.785\n",
      "[  23000] W:0.40662/4.2244, B:1.7221, Cost:13.473\n",
      "[  23500] W:0.40317/4.2323, B:1.7221, Cost:13.177\n",
      "[  24000] W:0.39982/ 4.24, B:1.7221, Cost:12.899\n",
      "[  24500] W:0.39657/4.2474, B:1.7221, Cost:12.635\n",
      "[  25000] W:0.39341/4.2546, B:1.7221, Cost:12.386\n",
      "[  25500] W:0.39033/4.2617, B:1.7221, Cost:12.15\n",
      "[  26000] W:0.38734/4.2685, B:1.7221, Cost:11.928\n",
      "[  26500] W:0.38443/4.2751, B:1.7221, Cost:11.717\n",
      "[  27000] W:0.38161/4.2816, B:1.7221, Cost:11.519\n",
      "[  27500] W:0.37886/4.2879, B:1.7221, Cost:11.331\n",
      "[  28000] W:0.37619/4.294, B:1.7221, Cost:11.153\n",
      "[  28500] W:0.37359/4.2999, B:1.7221, Cost:10.986\n",
      "[  29000] W:0.37107/4.3057, B:1.7221, Cost:10.827\n",
      "[  29500] W:0.36862/4.3113, B:1.7221, Cost:10.677\n",
      "[  30000] W:0.36623/4.3167, B:1.7221, Cost:10.536\n",
      "[  30500] W:0.36391/4.322, B:1.7221, Cost:10.402\n",
      "[  31000] W:0.36166/4.3272, B:1.7221, Cost:10.275\n",
      "[  31500] W:0.35947/4.3322, B:1.7221, Cost:10.156\n",
      "[  32000] W:0.35734/4.337, B:1.7221, Cost:10.043\n",
      "[  32500] W:0.35527/4.3418, B:1.7221, Cost:9.9361\n",
      "[  33000] W:0.35325/4.3464, B:1.7221, Cost:9.8352\n",
      "[  33500] W:0.35129/4.3509, B:1.7221, Cost:9.7398\n",
      "[  34000] W:0.34939/4.3552, B:1.7221, Cost:9.6497\n",
      "[  34500] W:0.34754/4.3594, B:1.7221, Cost:9.5646\n",
      "[  35000] W:0.34574/4.3635, B:1.7221, Cost:9.4841\n",
      "[  35500] W:0.344/4.3675, B:1.7221, Cost:9.408\n",
      "[  36000] W:0.3423/4.3714, B:1.7221, Cost:9.3361\n",
      "[  36500] W:0.34064/4.3752, B:1.7221, Cost:9.2682\n",
      "[  37000] W:0.33904/4.3789, B:1.7221, Cost:9.204\n",
      "[  37500] W:0.33748/4.3824, B:1.7221, Cost:9.1433\n",
      "[  38000] W:0.33596/4.3859, B:1.7221, Cost:9.086\n",
      "[  38500] W:0.33448/4.3893, B:1.7221, Cost:9.0318\n",
      "[  39000] W:0.33305/4.3925, B:1.7221, Cost:8.9806\n",
      "[  39500] W:0.33165/4.3957, B:1.7221, Cost:8.9322\n",
      "[  40000] W:0.3303/4.3988, B:1.7221, Cost:8.8865\n",
      "[  40500] W:0.32898/4.4018, B:1.7221, Cost:8.8432\n",
      "[  41000] W:0.3277/4.4048, B:1.7221, Cost:8.8024\n",
      "[  41500] W:0.32645/4.4076, B:1.7221, Cost:8.7638\n",
      "[  42000] W:0.32524/4.4104, B:1.7221, Cost:8.7273\n",
      "[  42500] W:0.32407/4.4131, B:1.7221, Cost:8.6928\n",
      "[  43000] W:0.32292/4.4157, B:1.7221, Cost:8.6602\n",
      "[  43500] W:0.32181/4.4182, B:1.7221, Cost:8.6294\n",
      "[  44000] W:0.32073/4.4207, B:1.7221, Cost:8.6003\n",
      "[  44500] W:0.31968/4.4231, B:1.7221, Cost:8.5728\n",
      "[  45000] W:0.31866/4.4254, B:1.7221, Cost:8.5468\n",
      "[  45500] W:0.31766/4.4277, B:1.7221, Cost:8.5222\n",
      "[  46000] W:0.3167/4.4299, B:1.7221, Cost:8.499\n",
      "[  46500] W:0.31576/4.4321, B:1.7221, Cost:8.4771\n",
      "[  47000] W:0.31484/4.4342, B:1.7221, Cost:8.4563\n",
      "[  47500] W:0.31396/4.4362, B:1.7221, Cost:8.4367\n",
      "[  48000] W:0.31309/4.4382, B:1.7221, Cost:8.4182\n",
      "[  48500] W:0.31226/4.4401, B:1.7221, Cost:8.4007\n",
      "[  49000] W:0.31144/4.4419, B:1.7221, Cost:8.3842\n",
      "[  49500] W:0.31065/4.4437, B:1.7221, Cost:8.3685\n",
      "[  50000] W:0.30988/4.4455, B:1.7221, Cost:8.3538\n",
      "[  50500] W:0.30913/4.4472, B:1.7221, Cost:8.3398\n",
      "[  51000] W:0.3084/4.4489, B:1.7221, Cost:8.3266\n",
      "[  51500] W:0.30769/4.4505, B:1.7221, Cost:8.3141\n",
      "[  52000] W:0.307/4.4521, B:1.7221, Cost:8.3023\n",
      "[  52500] W:0.30633/4.4536, B:1.7221, Cost:8.2912\n",
      "[  53000] W:0.30568/4.4551, B:1.7221, Cost:8.2807\n",
      "[  53500] W:0.30505/4.4565, B:1.7221, Cost:8.2707\n",
      "[  54000] W:0.30444/4.4579, B:1.7221, Cost:8.2613\n",
      "[  54500] W:0.30384/4.4593, B:1.7221, Cost:8.2524\n",
      "[  55000] W:0.30326/4.4606, B:1.7221, Cost:8.244\n",
      "[  55500] W:0.30269/4.4619, B:1.7221, Cost:8.2361\n",
      "[  56000] W:0.30215/4.4632, B:1.7221, Cost:8.2286\n",
      "[  56500] W:0.30161/4.4644, B:1.7221, Cost:8.2215\n",
      "[  57000] W:0.30109/4.4656, B:1.7221, Cost:8.2148\n",
      "[  57500] W:0.30059/4.4667, B:1.7221, Cost:8.2085\n",
      "[  58000] W:0.3001/4.4678, B:1.7221, Cost:8.2025\n",
      "[  58500] W:0.29962/4.4689, B:1.7221, Cost:8.1969\n",
      "[  59000] W:0.29916/ 4.47, B:1.7221, Cost:8.1915\n",
      "[  59500] W:0.29871/4.471, B:1.7221, Cost:8.1865\n",
      "[  60000] W:0.29827/4.472, B:1.7221, Cost:8.1817\n",
      "[  60500] W:0.29784/4.473, B:1.7221, Cost:8.1772\n",
      "[  61000] W:0.29743/4.4739, B:1.7221, Cost:8.1729\n",
      "[  61500] W:0.29703/4.4749, B:1.7221, Cost:8.1689\n",
      "[  62000] W:0.29664/4.4758, B:1.7221, Cost:8.1651\n",
      "[  62500] W:0.29626/4.4766, B:1.7221, Cost:8.1615\n",
      "[  63000] W:0.29589/4.4775, B:1.7221, Cost:8.1581\n",
      "[  63500] W:0.29553/4.4783, B:1.7221, Cost:8.1549\n",
      "[  64000] W:0.29518/4.4791, B:1.7221, Cost:8.1518\n",
      "[  64500] W:0.29484/4.4799, B:1.7221, Cost:8.149\n",
      "[  65000] W:0.29451/4.4806, B:1.7221, Cost:8.1462\n",
      "[  65500] W:0.29419/4.4814, B:1.7221, Cost:8.1437\n",
      "[  66000] W:0.29388/4.4821, B:1.7221, Cost:8.1413\n",
      "[  66500] W:0.29357/4.4828, B:1.7221, Cost:8.139\n",
      "[  67000] W:0.29328/4.4834, B:1.7221, Cost:8.1368\n",
      "[  67500] W:0.29299/4.4841, B:1.7221, Cost:8.1348\n",
      "[  68000] W:0.29271/4.4847, B:1.7221, Cost:8.1328\n",
      "[  68500] W:0.29244/4.4853, B:1.7221, Cost:8.131\n",
      "[  69000] W:0.29218/4.4859, B:1.7221, Cost:8.1293\n",
      "[  69500] W:0.29192/4.4865, B:1.7221, Cost:8.1276\n",
      "[  70000] W:0.29167/4.4871, B:1.7221, Cost:8.1261\n",
      "[  70500] W:0.29143/4.4877, B:1.7221, Cost:8.1246\n",
      "[  71000] W:0.2912/4.4882, B:1.7221, Cost:8.1233\n",
      "[  71500] W:0.29097/4.4887, B:1.7221, Cost:8.122\n",
      "[  72000] W:0.29075/4.4892, B:1.7221, Cost:8.1207\n",
      "[  72500] W:0.29053/4.4897, B:1.7221, Cost:8.1196\n",
      "[  73000] W:0.29032/4.4902, B:1.7221, Cost:8.1185\n",
      "[  73500] W:0.29012/4.4907, B:1.7221, Cost:8.1174\n",
      "[  74000] W:0.28992/4.4911, B:1.7221, Cost:8.1165\n",
      "[  74500] W:0.28972/4.4916, B:1.7221, Cost:8.1155\n",
      "[  75000] W:0.28954/4.492, B:1.7221, Cost:8.1147\n",
      "[  75500] W:0.28935/4.4924, B:1.7221, Cost:8.1138\n",
      "[  76000] W:0.28918/4.4928, B:1.7221, Cost:8.113\n",
      "[  76500] W:0.289/4.4932, B:1.7221, Cost:8.1123\n",
      "[  77000] W:0.28884/4.4936, B:1.7221, Cost:8.1116\n",
      "[  77500] W:0.28867/4.494, B:1.7221, Cost:8.1109\n",
      "[  78000] W:0.28852/4.4943, B:1.7221, Cost:8.1103\n",
      "[  78500] W:0.28836/4.4947, B:1.7221, Cost:8.1097\n",
      "[  79000] W:0.28821/4.495, B:1.7221, Cost:8.1092\n",
      "[  79500] W:0.28807/4.4953, B:1.7221, Cost:8.1086\n",
      "[  80000] W:0.28792/4.4957, B:1.7221, Cost:8.1081\n",
      "[  80500] W:0.28779/4.496, B:1.7221, Cost:8.1077\n",
      "[  81000] W:0.28765/4.4963, B:1.7221, Cost:8.1072\n",
      "[  81500] W:0.28752/4.4966, B:1.7221, Cost:8.1068\n",
      "[  82000] W:0.2874/4.4969, B:1.7221, Cost:8.1064\n",
      "[  82500] W:0.28727/4.4972, B:1.7221, Cost:8.106\n",
      "[  83000] W:0.28715/4.4974, B:1.7221, Cost:8.1057\n",
      "[  83500] W:0.28704/4.4977, B:1.7221, Cost:8.1054\n",
      "[  84000] W:0.28693/4.4979, B:1.7221, Cost:8.105\n",
      "[  84500] W:0.28682/4.4982, B:1.7221, Cost:8.1047\n",
      "[  85000] W:0.28671/4.4984, B:1.7221, Cost:8.1045\n",
      "[  85500] W:0.28661/4.4987, B:1.7221, Cost:8.1042\n",
      "[  86000] W:0.28651/4.4989, B:1.7221, Cost:8.1039\n",
      "[  86500] W:0.28641/4.4991, B:1.7221, Cost:8.1037\n",
      "[  87000] W:0.28631/4.4994, B:1.7221, Cost:8.1035\n",
      "[  87500] W:0.28622/4.4996, B:1.7221, Cost:8.1033\n",
      "[  88000] W:0.28613/4.4998, B:1.7221, Cost:8.1031\n",
      "[  88500] W:0.28604/  4.5, B:1.7221, Cost:8.1029\n",
      "[  89000] W:0.28596/4.5002, B:1.7221, Cost:8.1027\n",
      "[  89500] W:0.28587/4.5004, B:1.7221, Cost:8.1025\n",
      "[  90000] W:0.28579/4.5005, B:1.7221, Cost:8.1023\n",
      "[  90500] W:0.28572/4.5007, B:1.7221, Cost:8.1022\n",
      "[  91000] W:0.28564/4.5009, B:1.7221, Cost:8.1021\n",
      "[  91500] W:0.28557/4.5011, B:1.7221, Cost:8.1019\n",
      "[  92000] W:0.28549/4.5012, B:1.7221, Cost:8.1018\n",
      "[  92500] W:0.28542/4.5014, B:1.7221, Cost:8.1017\n",
      "[  93000] W:0.28536/4.5015, B:1.7221, Cost:8.1016\n",
      "[  93500] W:0.28529/4.5017, B:1.7221, Cost:8.1014\n",
      "[  94000] W:0.28523/4.5018, B:1.7221, Cost:8.1013\n",
      "[  94500] W:0.28516/4.502, B:1.7221, Cost:8.1012\n",
      "[  95000] W:0.2851/4.5021, B:1.7221, Cost:8.1012\n",
      "[  95500] W:0.28504/4.5022, B:1.7221, Cost:8.1011\n",
      "[  96000] W:0.28499/4.5024, B:1.7221, Cost:8.101\n",
      "[  96500] W:0.28493/4.5025, B:1.7221, Cost:8.1009\n",
      "[  97000] W:0.28488/4.5026, B:1.7221, Cost:8.1008\n",
      "[  97500] W:0.28482/4.5028, B:1.7221, Cost:8.1008\n",
      "[  98000] W:0.28477/4.5029, B:1.7221, Cost:8.1007\n",
      "[  98500] W:0.28472/4.503, B:1.7221, Cost:8.1006\n",
      "[  99000] W:0.28468/4.5031, B:1.7221, Cost:8.1006\n",
      "[  99500] W:0.28463/4.5032, B:1.7221, Cost:8.1005\n",
      "[ 100000] W:0.28458/4.5033, B:1.7221, Cost:8.1005\n",
      "CPU times: total: 7.19 s\n",
      "Wall time: 9.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 100000\n",
    "l_rate = 5e-7\n",
    "\n",
    "cost_graph = np.zeros(epochs+1)\n",
    "\n",
    "for i in range(0,epochs+1):\n",
    "    cost_graph[i] = Cost()\n",
    "    if (i%500)==0:\n",
    "        print(\"[{:>7}] W:{:>5.5}/{:>5.5}, B:{:>5.5}, Cost:{:>5.5}\".format(i,W[0,0],W[1,0],B,cost_graph[i]))\n",
    "    \n",
    "    grad_w, grad_b = Gradient()\n",
    "    W -= grad_w*l_rate\n",
    "    B -= grad_b*l_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]]),\n",
       " (5, 2),\n",
       " array([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]]),\n",
       " (2, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.arange(10)\n",
    "arr2 = arr1.reshape(5,-1)\n",
    "arr3 = arr1.reshape(2,-1)\n",
    "arr2, arr2.shape, arr3, arr3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 상황에 대한 그래프 출력\n",
    "# plt.title(\"'Cost / Epochs' Graph\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Cost\")\n",
    "plt.plot(training_idx, cost_graph)\n",
    "plt.xlim(0, epochs)\n",
    "# plt.grid(True)\n",
    "plt.semilogy()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex07"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
